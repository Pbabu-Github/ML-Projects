[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this bloghshjs"
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "Automated decision systems are increasingly used in financial institutions to assess credit risk and determine loan eligibility. In this blog post, we build upon the theoretical framework of binary decision-making with a linear score function, applying it to a more realistic credit-risk prediction scenario. Our goal is twofold: first, to develop a score function and threshold that optimize a bank’s total expected profit while considering various borrower features; and second, to assess how this decision system impacts different demographic segments. By leveraging data-driven modeling, visualization, and profit-based optimization, we aim to create a more informed and equitable approach to automated lending decisions."
  },
  {
    "objectID": "posts/new-new-test-post/index.html#math",
    "href": "posts/new-new-test-post/index.html#math",
    "title": "Classifying Palmer Penguins",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "Predicting a penguin’s species based on its physical measurements is an interesting challenge in data analysis and machine learning. In this blog, we’ll explore the Palmer Penguins dataset, which was collected by Dr. Kristen Gorman and the Palmer Station, to analyze biological measurements of three penguin species in Antarctica. Through data visualization and feature selection, we’ll uncover key insights and build a classification model that achieves perfect accuracy using a carefully chosen set of features. Along the way, we’ll discuss our findings and ensure a reproducible and insightful approach to species classification. ### Loading Data We will now use the Pandas function to read the CSV and also take a look at the data and the different variables and columns we have in our dataset before we do and data explorations and analysis.\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN"
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "Dissecting racial bias in an algorithm used to manage the health of populations\n\n\n\n\n\nA replication study of Obermeyer et al. (2019), exploring racial bias in healthcare cost algorithms and its impact on resource allocation.\n\n\n\n\n\nMar 2, 2025\n\n\nPB\n\n\n\n\n\n\n\n\n\n\n\n\nDesign and Impact of Automated Decision Systems\n\n\n\n\n\nA blog post about Design and Impact of Automated Decision Systems\n\n\n\n\n\nFeb 27, 2025\n\n\nPB\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying Palmer Penguins\n\n\n\n\n\nA blog post about classifying penguins with machine learning using logistic Regression.\n\n\n\n\n\nFeb 20, 2025\n\n\nPB\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/example-blog-post/index.html#data-cleaning",
    "href": "posts/example-blog-post/index.html#data-cleaning",
    "title": "Classifying Palmer Penguins",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nOur dataset contains numerous variables, including comments and region information, that are not relevant for training our model. Since we will be focusing on variables such as island, culmen length, culmen depth, flipper length, and body mass, we will remove unnecessary columns before proceeding with data exploration, visualization, and model training. Let’s start by loading the necessary packages for data cleaning, visualization, and model training. We will also convert categorical feature columns like Sex and Island into one-hot encoded 0-1( or true or false) columns using the pd.get_dummies function. Additionally, we can see that Species is a categorical variable, but instead of one-hot encoding, we will use label encoding to convert it into numerical labels: 0 for Adelie, 1 for Chinstrap, and 2 for Gentoo. This transformation will make data visualization and model training much easier.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC # support vector classifier\nfrom mlxtend.plotting import plot_decision_regions # for visualization later\nfrom sklearn.preprocessing import LabelEncoder\n\n# Encode categorical features and label\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n    df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\", \"Stage\"], axis=1)\n    df = df[df[\"Sex\"] != \".\"]\n    df = df.dropna()\n    y = le.transform(df[\"Species\"])\n    df = df.drop([\"Species\"], axis=1)\n    # One-hot encode categorical variables\n    df =(pd.get_dummies(df)).astype(int)\n\n    return df, y\n\n# Prepare training data\nX_train, y_train = prepare_data(train)\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40\n16\n187\n3200\n9\n-24\n0\n1\n0\n0\n1\n1\n0\n\n\n1\n49\n19\n210\n3950\n9\n-24\n0\n1\n0\n0\n1\n0\n1\n\n\n2\n50\n15\n218\n5700\n8\n-25\n1\n0\n0\n0\n1\n0\n1\n\n\n3\n45\n14\n210\n4200\n7\n-25\n1\n0\n0\n0\n1\n1\n0\n\n\n4\n51\n18\n203\n4100\n9\n-24\n0\n1\n0\n0\n1\n0\n1\n\n\n\n\n\n\n\n\nVisualizing the data\nThe bar chart below shows the number of penguins of each species on different islands, helping us identify patterns in species distribution. Interestingly, we observe: - Torgersen Island: Only Adelie penguins are present, with a population of about 30-40 individuals. - Dream Island: Has both Adelie and Chinstrap penguins, with Chinstrap being the dominant species. - Biscoe Island: Has both Adelie and Gentoo penguins, with Gentoo having the largest population overall.\nChinstrap penguins are only found on Dream Island, while Gentoo penguins are exclusive to Biscoe Island. Adelie penguins, on the other hand, are the most widespread, appearing on all three islands. Based on this distribution, the island where a penguin is found could be a useful feature for predicting its species.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n# Map species labels back to names\nspecies_map = {0: 'Adelie', 1: 'Chinstrap', 2: 'Gentoo'}\nspecies_island_counts = X_train.copy()\nspecies_island_counts[\"Species\"] = [species_map[label] for label in y_train]\n\n# Convert one-hot encoded islands back to a single column\nspecies_island_counts[\"Island\"] = species_island_counts[[\"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]].idxmax(axis=1)\nspecies_island_counts[\"Island\"] = species_island_counts[\"Island\"].str.replace(\"Island_\", \"\")\n\n# Count number of penguins per species per island\nplot_data = species_island_counts.groupby([\"Island\", \"Species\"]).size().reset_index(name=\"Count\")\n\n# Plot\nplt.figure(figsize=(8, 5))\nsns.barplot(data=plot_data, x=\"Island\", y=\"Count\", hue=\"Species\", palette=\"mako\")\nplt.xlabel(\"Island\")\nplt.ylabel(\"Number of Penguins\")\nplt.title(\"Penguin Species Distribution Across Islands\")\nplt.legend(title=\"Species\")\nplt.show()\n\n\n\n\n\n\n\n\nBased on the graph above, we can see that by simply looking at the islands, we can somewhat predict the species of the penguin. This is a good example of a feature that could help predict the species. However, the model would be much more efficient if each island only hosted one species of penguin. Since some islands have more than one species, we might want to explore additional features. For example, if a penguin is on Biscoe Island and has a certain Culmen length and Culmen depth, can we make more accurate predictions based on those measurements? To explore this, we will create a graph to assess whether including Culmen lenght and Culmen depth is a useful feature for predicting the species on each island.\n\n\n# Plotting the relationship between Culmen Length and Culmen Depth for each species on each island\nsns.relplot(data =train, hue=\"Species\", y = 'Culmen Depth (mm)', x =  'Culmen Length (mm)',col = 'Island')\n\n&lt;seaborn.axisgrid.FacetGrid at 0x149d2fc10&gt;\n\n\n\n\n\n\n\n\n\nThe graph above looks at the relationship between Culmen Depth (mm) and Culmen Length (mm) for different penguin species, separated by island. Each species is color-coded to highlight patterns in their beak dimensions. From this graph, we can observe: - Gentoo penguins (orange) tend to have longer culmen lengths and shallower culmen depths. - Adelie penguins (green) have moderate culmen lengths and a wide range of culmen depths. - Chinstrap penguins (blue) have longer culmen lenghts compared to Adelie penguins but exhibit similar culmen Depths. ## Can Culmen Features Help in Classification? Looking at the separability of species by island: - Biscoe Island: Gentoo and Adelie penguins are linearly separable, meaning a simple model could classify them effectively based on culmen features. - Dream Island: Chinstrap and Adelie penguins overlap in culmen depth, making them harder to separate linearly. However, their culmen lengths show some distinction, which could aid classification. - Torgersen Island: Since only Adelie penguins are found here, culmen features are irrelevant for classification on this island.\nThis suggests that culmen depth and length can be strong features for classifying species, especially when combined with island location. ## Exploring Culmen Features in relation to Flipper Lenght\n\nsns.relplot(data = train, y = 'Culmen Length (mm)', x =  'Flipper Length (mm)',  hue = 'Species').set(title='Relation between Flipper Length and Culmen Length')\nsns.relplot(data = train, y = 'Culmen Depth (mm)', x =  'Flipper Length (mm)',  hue = 'Species').set(title='Relation between Flipper Length and Culmen Depth')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe first graph explores the relationship between flipper length and culmen length across penguin species. Gentoo penguins have both longer flipper lengths and culmen lengths compared to the other species, making them easily distinguishable. Adelie penguins, in contrast, have shorter values for both features, clustering in the lower-left section of the graph. Chinstrap penguins overlap with Adelie penguins in flipper length but tend to have slightly longer culmen lengths, creating some classification challenges.\nThe second graph examines the relationship between flipper length and culmen depth. Here, Gentoo penguins are clearly separable from the other two species due to their significantly shallower culmen depths, forming a distinct cluster in the lower section. Howeber the Adelie and Chinstrap penguins overlap a lot more, particularly in flipper length and culmen depth. While Gentoo penguins can be classified easily, distinguishing between Adelie and Chinstrap penguins would be really difficult because of this clustering.\n\ntrain.groupby('Species').agg({\n    'Flipper Length (mm)': 'mean',\n    'Culmen Length (mm)': 'mean',\n    'Culmen Depth (mm)': 'mean'\n}).reset_index()\n\n\n\n\n\n\n\n\nSpecies\nFlipper Length (mm)\nCulmen Length (mm)\nCulmen Depth (mm)\n\n\n\n\n0\nAdelie Penguin (Pygoscelis adeliae)\n190.084034\n38.970588\n18.409244\n\n\n1\nChinstrap penguin (Pygoscelis antarctica)\n196.000000\n48.826316\n18.366667\n\n\n2\nGentoo penguin (Pygoscelis papua)\n216.752577\n47.073196\n14.914433\n\n\n\n\n\n\n\nThis code above calculates the mean values of flipper length, culmen length, and culmen depth for each penguin species using the .groupby() function. The table summarizes the average flipper length, culmen length, and culmen depth for each penguin species. Gentoo penguins have the longest flipper and culmen lengths but the shallowest culmen depth. Chinstrap penguins have longer culmen lengths than Adelie penguins but similar culmen depths. Adelie penguins have the shortest flipper and culmen lengths but slightly deeper culmens than Chinstrap. These differences highlight key features that can help classify penguin species."
  },
  {
    "objectID": "posts/example-blog-post/index.html#now-we-are-going-to-chose-feature-to-train-our-model",
    "href": "posts/example-blog-post/index.html#now-we-are-going-to-chose-feature-to-train-our-model",
    "title": "Classifying Palmer Penguins",
    "section": "Now we are going to chose feature to train our model",
    "text": "Now we are going to chose feature to train our model\nBy using the combinations function from the itertools package, we generate different combinations of categorical and continuous features. So we will pair categorical variables like Sex and Clutch Completion with continuous variables such as Culmen Length, Culmen Depth, and Flipper Length. This allows us to explore various feature combinations and evaluate which ones might be most useful for accurately classifying the penguin species.\n\nfrom itertools import combinations\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\n\nbest_score = 0\nbest_features = None\n\nfor qual in all_qual_cols:\n    qual_cols = [col for col in X_train.columns if qual in col]  # Ensure categorical features are one-hot encoded\n    for pair in combinations(all_quant_cols, 2):\n        cols = qual_cols + list(pair)\n        \n        # Train a logistic regression model to evaluate feature combinations\n        model = LogisticRegression(max_iter=1000)  # Increased iterations for better convergence\n        scores = cross_val_score(model, X_train[cols], y_train, cv=5, scoring='accuracy')\n        \n        avg_score = np.mean(scores)\n        if avg_score &gt; best_score:\n            best_score = avg_score\n            best_features = cols\n\nprint(\"Best features:\", best_features)\n\nBest features: ['Sex_FEMALE', 'Sex_MALE', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n\n\nAccording to itertools, the best features to use are ‘Sex_FEMALE’, ‘Sex_MALE’, ‘Culmen Length (mm)’, and ‘Culmen Depth (mm)’. However, we wanted to explore how our model would perform based on our exploration of the island features along with the Culmen features. Thus, we will now reassign these as the best features and use them to train our model.\n\n#Rearranging Best featrues so that the first two columns are the quantitative columns and the rest are the qualitative columns\nbest_features = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\nbest_features\n\n['Culmen Length (mm)',\n 'Culmen Depth (mm)',\n 'Island_Biscoe',\n 'Island_Dream',\n 'Island_Torgersen']"
  },
  {
    "objectID": "posts/example-blog-post/index.html#let-us-now-prepare-our-test-dataset",
    "href": "posts/example-blog-post/index.html#let-us-now-prepare-our-test-dataset",
    "title": "Classifying Palmer Penguins",
    "section": "Let us now prepare our Test Dataset",
    "text": "Let us now prepare our Test Dataset\n\n# Load test data\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\n# Prepare test data\nX_test, y_test = prepare_data(test)"
  },
  {
    "objectID": "posts/example-blog-post/index.html#training-and-evaluating-our-model",
    "href": "posts/example-blog-post/index.html#training-and-evaluating-our-model",
    "title": "Classifying Palmer Penguins",
    "section": "Training and evaluating our Model",
    "text": "Training and evaluating our Model\nIn the code below, we use a Logistic Regression model and train it on the selected features: [‘Culmen Length (mm)’, ‘Culmen Depth (mm)’, ‘Island_Biscoe’, ‘Island_Dream’, ‘Island_Torgersen’]. We then evaluate the accuracy using the LR.score function. Our training accuracy was 99%, and our testing accuracy—measuring how well the model performed on unseen data—was 100%. The confusion matrix confirms that we correctly classified all penguins with no misclassifications. Specifically, our model correctly identified 31 Adelie, 11 Chinstrap, and 26 Gentoo penguins, achieving perfect classification.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nLR = LogisticRegression()\nLR.fit(X_train[best_features], y_train)\n\n\n\n# Predict on test set\ny_pred = LR.predict(X_test[best_features])\n\n# Evaluate the model\nscore_train = LR.score(X_train[best_features], y_train)\nscore_test = LR.score(X_test[best_features], y_test)\n\nprint(\"Training Accuracy:\", score_train)\nprint(\"Test Accuracy:\", score_test)\n\nprint(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n\nTraining Accuracy: 0.9921875\nTest Accuracy: 1.0\n\nConfusion Matrix:\n [[31  0  0]\n [ 0 11  0]\n [ 0  0 26]]"
  },
  {
    "objectID": "posts/example-blog-post/index.html#plotting-our-results",
    "href": "posts/example-blog-post/index.html#plotting-our-results",
    "title": "Classifying Palmer Penguins",
    "section": "Plotting our results",
    "text": "Plotting our results\nThis code below helps us visualize the decision regions of our classification model by plotting how different penguin species are separated based on culmen features and island locations. It creates a grid of values for the culmen length and depth, predicts species across the grid. Each subplot represents a different island, showing how the model’s decision boundaries change depending on the island feature. This helps us understand how the model differentiates between Adelie, Chinstrap, and Gentoo penguins on each island.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y, title):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize=(7 * len(qual_features), 3))  # doing this to fit three plots side by side\n    fig.suptitle(title, fontsize=14)\n\n    # Create a grid\n    grid_x = np.linspace(x0.min(), x0.max(), 501)\n    grid_y = np.linspace(x1.min(), x1.max(), 501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    if len(qual_features) == 1:\n        axarr = [axarr] \n\n    for i, ax in enumerate(axarr):\n        XY = pd.DataFrame({\n            X.columns[0]: XX,\n            X.columns[1]: YY\n        })\n\n        for j in qual_features:\n            XY[j] = 0\n\n        XY[qual_features[i]] = 1\n\n        p = model.predict(XY)\n        p = p.reshape(xx.shape)\n        \n        # Use contour plot to visualize the predictions\n        ax.contourf(xx, yy, p, cmap=\"jet\", alpha=0.2, vmin=0, vmax=2)\n\n        ix = X[qual_features[i]] == 1\n        ax.scatter(x0[ix], x1[ix], c=y[ix], cmap=\"jet\", vmin=0, vmax=2)\n        \n        ax.set(xlabel=X.columns[0], ylabel=X.columns[1], title=qual_features[i])\n\n    patches = [Patch(color=color, label=spec) for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"])]\n    fig.legend(handles=patches, title=\"Species\", loc=\"upper right\")\n\n    plt.tight_layout(rect=[0, 0, 0.9, 1])\n    plt.show()\n\n# Run function for training and test sets\nplot_regions(LR, X_train[best_features], y_train, title=\"Training Set\")\nplot_regions(LR, X_test[best_features], y_pred, title=\"Test Set\")"
  },
  {
    "objectID": "posts/example-blog-post/blog1.html",
    "href": "posts/example-blog-post/blog1.html",
    "title": "Goal of Project",
    "section": "",
    "text": "---\ntitle: Hello Blog\nauthor: PB\ndate: '2025-02-20'\nimage: \"image.jpg\"\ndescription: \"A Blog post about classifying penguins with machine learning.\"\nformat: html\n---\nPredicting a penguin’s species based on its physical measurements is an interesting challenge in data analysis and machine learning. In this blog, we’ll explore the Palmer Penguins dataset, which was collected by Dr. Kristen Gorman and the Palmer Station, to analyze biological measurements of three penguin species in Antarctica. Through data visualization and feature selection, we’ll uncover key insights and build a classification model that achieves perfect accuracy using a carefully chosen set of features. Along the way, we’ll discuss our findings and ensure a reproducible and insightful approach to species classification. ### Loading Data We will now use the Pandas function to read the CSV and also take a look at the data and the different variables and columns we have in our dataset before we do and data explorations and analysis.\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN"
  },
  {
    "objectID": "posts/example-blog-post/blog1.html#data-cleaning",
    "href": "posts/example-blog-post/blog1.html#data-cleaning",
    "title": "Goal of Project",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nOur dataset contains numerous variables, including comments and region information, that are not relevant for training our model. Since we will be focusing on variables such as island, culmen length, culmen depth, flipper length, and body mass, we will remove unnecessary columns before proceeding with data exploration, visualization, and model training. Let’s start by loading the necessary packages for data cleaning, visualization, and model training. We will also convert categorical feature columns like Sex and Island into one-hot encoded 0-1( or true or false) columns using the pd.get_dummies function. Additionally, we can see that Species is a categorical variable, but instead of one-hot encoding, we will use label encoding to convert it into numerical labels: 0 for Adelie, 1 for Chinstrap, and 2 for Gentoo. This transformation will make data visualization and model training much easier.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC # support vector classifier\nfrom mlxtend.plotting import plot_decision_regions # for visualization later\nfrom sklearn.preprocessing import LabelEncoder\n\n# Encode categorical features and label\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n    df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\", \"Stage\"], axis=1)\n    df = df[df[\"Sex\"] != \".\"]\n    df = df.dropna()\n    y = le.transform(df[\"Species\"])\n    df = df.drop([\"Species\"], axis=1)\n    # One-hot encode categorical variables\n    df =(pd.get_dummies(df)).astype(int)\n\n    return df, y\n\n# Prepare training data\nX_train, y_train = prepare_data(train)\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40\n16\n187\n3200\n9\n-24\n0\n1\n0\n0\n1\n1\n0\n\n\n1\n49\n19\n210\n3950\n9\n-24\n0\n1\n0\n0\n1\n0\n1\n\n\n2\n50\n15\n218\n5700\n8\n-25\n1\n0\n0\n0\n1\n0\n1\n\n\n3\n45\n14\n210\n4200\n7\n-25\n1\n0\n0\n0\n1\n1\n0\n\n\n4\n51\n18\n203\n4100\n9\n-24\n0\n1\n0\n0\n1\n0\n1\n\n\n\n\n\n\n\n\nVisualizing the data\nThe bar chart below shows the number of penguins of each species on different islands, helping us identify patterns in species distribution. Interestingly, we observe: - Torgersen Island: Only Adelie penguins are present, with a population of about 30-40 individuals. - Dream Island: Has both Adelie and Chinstrap penguins, with Chinstrap being the dominant species. - Biscoe Island: Has both Adelie and Gentoo penguins, with Gentoo having the largest population overall.\nChinstrap penguins are only found on Dream Island, while Gentoo penguins are exclusive to Biscoe Island. Adelie penguins, on the other hand, are the most widespread, appearing on all three islands. Based on this distribution, the island where a penguin is found could be a useful feature for predicting its species.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n# Map species labels back to names\nspecies_map = {0: 'Adelie', 1: 'Chinstrap', 2: 'Gentoo'}\nspecies_island_counts = X_train.copy()\nspecies_island_counts[\"Species\"] = [species_map[label] for label in y_train]\n\n# Convert one-hot encoded islands back to a single column\nspecies_island_counts[\"Island\"] = species_island_counts[[\"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]].idxmax(axis=1)\nspecies_island_counts[\"Island\"] = species_island_counts[\"Island\"].str.replace(\"Island_\", \"\")\n\n# Count number of penguins per species per island\nplot_data = species_island_counts.groupby([\"Island\", \"Species\"]).size().reset_index(name=\"Count\")\n\n# Plot\nplt.figure(figsize=(8, 5))\nsns.barplot(data=plot_data, x=\"Island\", y=\"Count\", hue=\"Species\", palette=\"mako\")\nplt.xlabel(\"Island\")\nplt.ylabel(\"Number of Penguins\")\nplt.title(\"Penguin Species Distribution Across Islands\")\nplt.legend(title=\"Species\")\nplt.show()\n\n\n\n\n\n\n\n\nBased on the graph above, we can see that by simply looking at the islands, we can somewhat predict the species of the penguin. This is a good example of a feature that could help predict the species. However, the model would be much more efficient if each island only hosted one species of penguin. Since some islands have more than one species, we might want to explore additional features. For example, if a penguin is on Biscoe Island and has a certain Culmen length and Culmen depth, can we make more accurate predictions based on those measurements? To explore this, we will create a graph to assess whether including Culmen lenght and Culmen depth is a useful feature for predicting the species on each island.\n\n\n# Plotting the relationship between Culmen Length and Culmen Depth for each species on each island\nsns.relplot(data =train, hue=\"Species\", y = 'Culmen Depth (mm)', x =  'Culmen Length (mm)',col = 'Island')\n\n\n\n\n\n\n\n\nThe graph above looks at the relationship between Culmen Depth (mm) and Culmen Length (mm) for different penguin species, separated by island. Each species is color-coded to highlight patterns in their beak dimensions. From this graph, we can observe: - Gentoo penguins (orange) tend to have longer culmen lengths and shallower culmen depths. - Adelie penguins (green) have moderate culmen lengths and a wide range of culmen depths. - Chinstrap penguins (blue) have longer culmen lenghts compared to Adelie penguins but exhibit similar culmen Depths. ## Can Culmen Features Help in Classification? Looking at the separability of species by island: - Biscoe Island: Gentoo and Adelie penguins are linearly separable, meaning a simple model could classify them effectively based on culmen features. - Dream Island: Chinstrap and Adelie penguins overlap in culmen depth, making them harder to separate linearly. However, their culmen lengths show some distinction, which could aid classification. - Torgersen Island: Since only Adelie penguins are found here, culmen features are irrelevant for classification on this island.\nThis suggests that culmen depth and length can be strong features for classifying species, especially when combined with island location. ## Exploring Culmen Features in relation to Flipper Lenght\n\nsns.relplot(data = train, y = 'Culmen Length (mm)', x =  'Flipper Length (mm)',  hue = 'Species').set(title='Relation between Flipper Length and Culmen Length')\nsns.relplot(data = train, y = 'Culmen Depth (mm)', x =  'Flipper Length (mm)',  hue = 'Species').set(title='Relation between Flipper Length and Culmen Depth')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe first graph explores the relationship between flipper length and culmen length across penguin species. Gentoo penguins have both longer flipper lengths and culmen lengths compared to the other species, making them easily distinguishable. Adelie penguins, in contrast, have shorter values for both features, clustering in the lower-left section of the graph. Chinstrap penguins overlap with Adelie penguins in flipper length but tend to have slightly longer culmen lengths, creating some classification challenges.\nThe second graph examines the relationship between flipper length and culmen depth. Here, Gentoo penguins are clearly separable from the other two species due to their significantly shallower culmen depths, forming a distinct cluster in the lower section. Howeber the Adelie and Chinstrap penguins overlap a lot more, particularly in flipper length and culmen depth. While Gentoo penguins can be classified easily, distinguishing between Adelie and Chinstrap penguins would be really difficult because of this clustering.\n\ntrain.groupby('Species').agg({\n    'Flipper Length (mm)': 'mean',\n    'Culmen Length (mm)': 'mean',\n    'Culmen Depth (mm)': 'mean'\n}).reset_index()\n\n\n\n\n\n\n\n\nSpecies\nFlipper Length (mm)\nCulmen Length (mm)\nCulmen Depth (mm)\n\n\n\n\n0\nAdelie Penguin (Pygoscelis adeliae)\n190.084034\n38.970588\n18.409244\n\n\n1\nChinstrap penguin (Pygoscelis antarctica)\n196.000000\n48.826316\n18.366667\n\n\n2\nGentoo penguin (Pygoscelis papua)\n216.752577\n47.073196\n14.914433\n\n\n\n\n\n\n\nThis code above calculates the mean values of flipper length, culmen length, and culmen depth for each penguin species using the .groupby() function. The table summarizes the average flipper length, culmen length, and culmen depth for each penguin species. Gentoo penguins have the longest flipper and culmen lengths but the shallowest culmen depth. Chinstrap penguins have longer culmen lengths than Adelie penguins but similar culmen depths. Adelie penguins have the shortest flipper and culmen lengths but slightly deeper culmens than Chinstrap. These differences highlight key features that can help classify penguin species."
  },
  {
    "objectID": "posts/example-blog-post/blog1.html#now-we-are-going-to-chose-feature-to-train-our-model",
    "href": "posts/example-blog-post/blog1.html#now-we-are-going-to-chose-feature-to-train-our-model",
    "title": "Goal of Project",
    "section": "Now we are going to chose feature to train our model",
    "text": "Now we are going to chose feature to train our model\nBy using the combinations function from the itertools package, we generate different combinations of categorical and continuous features. So we will pair categorical variables like Sex and Clutch Completion with continuous variables such as Culmen Length, Culmen Depth, and Flipper Length. This allows us to explore various feature combinations and evaluate which ones might be most useful for accurately classifying the penguin species.\n\nfrom itertools import combinations\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\n\nbest_score = 0\nbest_features = None\n\nfor qual in all_qual_cols:\n    qual_cols = [col for col in X_train.columns if qual in col]  # Ensure categorical features are one-hot encoded\n    for pair in combinations(all_quant_cols, 2):\n        cols = qual_cols + list(pair)\n        \n        # Train a logistic regression model to evaluate feature combinations\n        model = LogisticRegression(max_iter=1000)  # Increased iterations for better convergence\n        scores = cross_val_score(model, X_train[cols], y_train, cv=5, scoring='accuracy')\n        \n        avg_score = np.mean(scores)\n        if avg_score &gt; best_score:\n            best_score = avg_score\n            best_features = cols\n\nprint(\"Best features:\", best_features)\n\nBest features: ['Sex_FEMALE', 'Sex_MALE', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n\n\nAccording to itertools, the best features to use are ‘Sex_FEMALE’, ‘Sex_MALE’, ‘Culmen Length (mm)’, and ‘Culmen Depth (mm)’. However, we wanted to explore how our model would perform based on our exploration of the island features along with the Culmen features. Thus, we will now reassign these as the best features and use them to train our model.\n\n#Rearranging Best featrues so that the first two columns are the quantitative columns and the rest are the qualitative columns\nbest_features = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\nbest_features\n\n['Culmen Length (mm)',\n 'Culmen Depth (mm)',\n 'Island_Biscoe',\n 'Island_Dream',\n 'Island_Torgersen']"
  },
  {
    "objectID": "posts/example-blog-post/blog1.html#let-us-now-prepare-our-test-dataset",
    "href": "posts/example-blog-post/blog1.html#let-us-now-prepare-our-test-dataset",
    "title": "Goal of Project",
    "section": "Let us now prepare our Test Dataset",
    "text": "Let us now prepare our Test Dataset\n\n# Load test data\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\n# Prepare test data\nX_test, y_test = prepare_data(test)"
  },
  {
    "objectID": "posts/example-blog-post/blog1.html#training-and-evaluating-our-model",
    "href": "posts/example-blog-post/blog1.html#training-and-evaluating-our-model",
    "title": "Goal of Project",
    "section": "Training and evaluating our Model",
    "text": "Training and evaluating our Model\nIn the code below, we use a Logistic Regression model and train it on the selected features: [‘Culmen Length (mm)’, ‘Culmen Depth (mm)’, ‘Island_Biscoe’, ‘Island_Dream’, ‘Island_Torgersen’]. We then evaluate the accuracy using the LR.score function. Our training accuracy was 99%, and our testing accuracy—measuring how well the model performed on unseen data—was 100%. The confusion matrix confirms that we correctly classified all penguins with no misclassifications. Specifically, our model correctly identified 31 Adelie, 11 Chinstrap, and 26 Gentoo penguins, achieving perfect classification.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nLR = LogisticRegression()\nLR.fit(X_train[best_features], y_train)\n\n\n\n# Predict on test set\ny_pred = LR.predict(X_test[best_features])\n\n# Evaluate the model\nscore_train = LR.score(X_train[best_features], y_train)\nscore_test = LR.score(X_test[best_features], y_test)\n\nprint(\"Training Accuracy:\", score_train)\nprint(\"Test Accuracy:\", score_test)\n\nprint(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n\nTraining Accuracy: 0.9921875\nTest Accuracy: 1.0\n\nConfusion Matrix:\n [[31  0  0]\n [ 0 11  0]\n [ 0  0 26]]"
  },
  {
    "objectID": "posts/example-blog-post/blog1.html#plotting-our-results",
    "href": "posts/example-blog-post/blog1.html#plotting-our-results",
    "title": "Goal of Project",
    "section": "Plotting our results",
    "text": "Plotting our results\nThis code below helps us visualize the decision regions of our classification model by plotting how different penguin species are separated based on culmen features and island locations. It creates a grid of values for the culmen length and depth, predicts species across the grid. Each subplot represents a different island, showing how the model’s decision boundaries change depending on the island feature. This helps us understand how the model differentiates between Adelie, Chinstrap, and Gentoo penguins on each island.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y, title):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize=(7 * len(qual_features), 3))  # doing this to fit three plots side by side\n    fig.suptitle(title, fontsize=14)\n\n    # Create a grid\n    grid_x = np.linspace(x0.min(), x0.max(), 501)\n    grid_y = np.linspace(x1.min(), x1.max(), 501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    if len(qual_features) == 1:\n        axarr = [axarr] \n\n    for i, ax in enumerate(axarr):\n        XY = pd.DataFrame({\n            X.columns[0]: XX,\n            X.columns[1]: YY\n        })\n\n        for j in qual_features:\n            XY[j] = 0\n\n        XY[qual_features[i]] = 1\n\n        p = model.predict(XY)\n        p = p.reshape(xx.shape)\n        \n        # Use contour plot to visualize the predictions\n        ax.contourf(xx, yy, p, cmap=\"jet\", alpha=0.2, vmin=0, vmax=2)\n\n        ix = X[qual_features[i]] == 1\n        ax.scatter(x0[ix], x1[ix], c=y[ix], cmap=\"jet\", vmin=0, vmax=2)\n        \n        ax.set(xlabel=X.columns[0], ylabel=X.columns[1], title=qual_features[i])\n\n    patches = [Patch(color=color, label=spec) for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"])]\n    fig.legend(handles=patches, title=\"Species\", loc=\"upper right\")\n\n    plt.tight_layout(rect=[0, 0, 0.9, 1])\n    plt.show()\n\n# Run function for training and test sets\nplot_regions(LR, X_train[best_features], y_train, title=\"Training Set\")\nplot_regions(LR, X_test[best_features], y_pred, title=\"Test Set\")"
  },
  {
    "objectID": "posts/Penguins/index.html",
    "href": "posts/Penguins/index.html",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "The Palmer Penguins dataset, collected by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, provides physiological measurements for three species of penguins—Adélie, Chinstrap, and Gentoo—inhabiting the Palmer Archipelago. First published in 2014 and later made widely accessible to the data science community, this dataset serves as a valuable resource for exploring classification techniques and species differentiation. In this blog post, I analyze the dataset using machine learning models to classify penguin species based on features such as flipper length, body mass, and culmen dimensions. By analyzing physical measurements we identify key features that contribute to accurate species prediction. Through data visualization and feature selection, we uncover patterns that distinguish species based on island location and physical traits. Using logistic regression, we evaluate different feature combinations and determine an optimal set for classification and acheive a 99% training accuracy and a 100% testing accuracy. Our findings highlight the power of data-driven approaches in biological classification while ensuring a reproducible and insightful methodology."
  },
  {
    "objectID": "posts/Penguins/index.html#data-cleaning",
    "href": "posts/Penguins/index.html#data-cleaning",
    "title": "Classifying Palmer Penguins",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nOur dataset contains numerous variables, including comments and region information, that are not relevant for training our model. Since we will be focusing on variables such as island, culmen length, culmen depth, flipper length, and body mass, we will remove unnecessary columns before proceeding with data exploration, visualization, and model training. Let’s start by loading the necessary packages for data cleaning, visualization, and model training. We will also convert categorical feature columns like Sex and Island into one-hot encoded 0-1( or true or false) columns using the pd.get_dummies function. Additionally, we can see that Species is a categorical variable, but instead of one-hot encoding, we will use label encoding to convert it into numerical labels: 0 for Adelie, 1 for Chinstrap, and 2 for Gentoo. This transformation will make data visualization and model training much easier.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC # support vector classifier\nfrom mlxtend.plotting import plot_decision_regions # for visualization later\nfrom sklearn.preprocessing import LabelEncoder\n\n# Encode categorical features and label\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n    df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\", \"Stage\"], axis=1)\n    df = df[df[\"Sex\"] != \".\"]\n    df = df.dropna()\n    y = le.transform(df[\"Species\"])\n    df = df.drop([\"Species\"], axis=1)\n    # One-hot encode categorical variables\n    df =(pd.get_dummies(df)).astype(int)\n\n    return df, y\n\n# Prepare training data\nX_train, y_train = prepare_data(train)\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40\n16\n187\n3200\n9\n-24\n0\n1\n0\n0\n1\n1\n0\n\n\n1\n49\n19\n210\n3950\n9\n-24\n0\n1\n0\n0\n1\n0\n1\n\n\n2\n50\n15\n218\n5700\n8\n-25\n1\n0\n0\n0\n1\n0\n1\n\n\n3\n45\n14\n210\n4200\n7\n-25\n1\n0\n0\n0\n1\n1\n0\n\n\n4\n51\n18\n203\n4100\n9\n-24\n0\n1\n0\n0\n1\n0\n1"
  },
  {
    "objectID": "posts/Penguins/index.html#now-we-are-going-to-chose-feature-to-train-our-model",
    "href": "posts/Penguins/index.html#now-we-are-going-to-chose-feature-to-train-our-model",
    "title": "Classifying Palmer Penguins",
    "section": "Now we are going to chose feature to train our model",
    "text": "Now we are going to chose feature to train our model\nBy using the combinations function from the itertools package, we generate different combinations of categorical and continuous features. So we will pair categorical variables like Sex and Clutch Completion with continuous variables such as Culmen Length, Culmen Depth, and Flipper Length. This allows us to explore various feature combinations and evaluate which ones might be most useful for accurately classifying the penguin species.\n\nfrom itertools import combinations\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\n\nbest_score = 0\nbest_features = None\n\nfor qual in all_qual_cols:\n    qual_cols = [col for col in X_train.columns if qual in col]  # Ensure categorical features are one-hot encoded\n    for pair in combinations(all_quant_cols, 2):\n        cols = qual_cols + list(pair)\n        \n        # Train a logistic regression model to evaluate feature combinations\n        model = LogisticRegression(max_iter=1000)  # Increased iterations for better convergence\n        scores = cross_val_score(model, X_train[cols], y_train, cv=5, scoring='accuracy')\n        \n        avg_score = np.mean(scores)\n        if avg_score &gt; best_score:\n            best_score = avg_score\n            best_features = cols\n\nprint(\"Best features:\", best_features)\n\nBest features: ['Sex_FEMALE', 'Sex_MALE', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n\n\nAccording to itertools, the best features to use are ‘Sex_FEMALE’, ‘Sex_MALE’, ‘Culmen Length (mm)’, and ‘Culmen Depth (mm)’. However, we wanted to explore how our model would perform based on our exploration of the island features along with the Culmen features. Thus, we will now reassign these as the best features and use them to train our model.\n\n#Rearranging Best featrues so that the first two columns are the quantitative columns and the rest are the qualitative columns\nbest_features = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\nbest_features\n\n['Culmen Length (mm)',\n 'Culmen Depth (mm)',\n 'Island_Biscoe',\n 'Island_Dream',\n 'Island_Torgersen']"
  },
  {
    "objectID": "posts/Penguins/index.html#let-us-now-prepare-our-test-dataset",
    "href": "posts/Penguins/index.html#let-us-now-prepare-our-test-dataset",
    "title": "Classifying Palmer Penguins",
    "section": "Let us now prepare our Test Dataset",
    "text": "Let us now prepare our Test Dataset\n\n# Load test data\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\n# Prepare test data\nX_test, y_test = prepare_data(test)"
  },
  {
    "objectID": "posts/Penguins/index.html#training-and-evaluating-our-model",
    "href": "posts/Penguins/index.html#training-and-evaluating-our-model",
    "title": "Classifying Palmer Penguins",
    "section": "Training and evaluating our Model",
    "text": "Training and evaluating our Model\nIn the code below, we use a Logistic Regression model and train it on the selected features: [‘Culmen Length (mm)’, ‘Culmen Depth (mm)’, ‘Island_Biscoe’, ‘Island_Dream’, ‘Island_Torgersen’]. We then evaluate the accuracy using the LR.score function. Our training accuracy was 99%, and our testing accuracy—measuring how well the model performed on unseen data—was 100%. The confusion matrix confirms that we correctly classified all penguins with no misclassifications. Specifically, our model correctly identified 31 Adelie, 11 Chinstrap, and 26 Gentoo penguins, achieving perfect classification.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nLR = LogisticRegression()\nLR.fit(X_train[best_features], y_train)\n\n\n\n# Predict on test set\ny_pred = LR.predict(X_test[best_features])\n\n# Evaluate the model\nscore_train = LR.score(X_train[best_features], y_train)\nscore_test = LR.score(X_test[best_features], y_test)\n\nprint(\"Training Accuracy:\", score_train)\nprint(\"Test Accuracy:\", score_test)\n\nprint(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n\nTraining Accuracy: 0.9921875\nTest Accuracy: 1.0\n\nConfusion Matrix:\n [[31  0  0]\n [ 0 11  0]\n [ 0  0 26]]"
  },
  {
    "objectID": "posts/Penguins/index.html#plotting-our-results",
    "href": "posts/Penguins/index.html#plotting-our-results",
    "title": "Classifying Palmer Penguins",
    "section": "Plotting our results",
    "text": "Plotting our results\nThis code below helps us visualize the decision regions of our classification model by plotting how different penguin species are separated based on culmen features and island locations. It creates a grid of values for the culmen length and depth, predicts species across the grid. Each subplot represents a different island, showing how the model’s decision boundaries change depending on the island feature. This helps us understand how the model differentiates between Adelie, Chinstrap, and Gentoo penguins on each island.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y, title):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize=(7 * len(qual_features), 3))  # doing this to fit three plots side by side\n    fig.suptitle(title, fontsize=14)\n\n    # Create a grid\n    grid_x = np.linspace(x0.min(), x0.max(), 501)\n    grid_y = np.linspace(x1.min(), x1.max(), 501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    if len(qual_features) == 1:\n        axarr = [axarr] \n\n    for i, ax in enumerate(axarr):\n        XY = pd.DataFrame({\n            X.columns[0]: XX,\n            X.columns[1]: YY\n        })\n\n        for j in qual_features:\n            XY[j] = 0\n\n        XY[qual_features[i]] = 1\n\n        p = model.predict(XY)\n        p = p.reshape(xx.shape)\n        \n        # Use contour plot to visualize the predictions\n        ax.contourf(xx, yy, p, cmap=\"jet\", alpha=0.2, vmin=0, vmax=2)\n\n        ix = X[qual_features[i]] == 1\n        ax.scatter(x0[ix], x1[ix], c=y[ix], cmap=\"jet\", vmin=0, vmax=2)\n        \n        ax.set(xlabel=X.columns[0], ylabel=X.columns[1], title=qual_features[i])\n\n    patches = [Patch(color=color, label=spec) for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"])]\n    fig.legend(handles=patches, title=\"Species\", loc=\"upper right\")\n\n    plt.tight_layout(rect=[0, 0, 0.9, 1])\n    plt.show()\n\n# Run function for training and test sets\nplot_regions(LR, X_train[best_features], y_train, title=\"Training Set\")\nplot_regions(LR, X_test[best_features], y_pred, title=\"Test Set\")"
  },
  {
    "objectID": "posts/Penguins/index.html#can-culmen-features-help-in-classification",
    "href": "posts/Penguins/index.html#can-culmen-features-help-in-classification",
    "title": "Classifying Palmer Penguins",
    "section": "Can Culmen Features Help in Classification?",
    "text": "Can Culmen Features Help in Classification?\nLooking at the separability of species by island:\n\nBiscoe Island: Gentoo and Adelie penguins are linearly separable, meaning a simple model could classify them effectively based on culmen features.\nDream Island: Chinstrap and Adelie penguins overlap in culmen depth, making them harder to separate linearly. However, their culmen lengths show some distinction, which could aid classification.\nTorgersen Island: Since only Adelie penguins are found here, culmen features are irrelevant for classification on this island.\n\nThis suggests that culmen depth and length can be strong features for classifying species, especially when combined with island location."
  },
  {
    "objectID": "posts/Penguins/index.html#exploring-culmen-features-in-relation-to-flipper-lenght",
    "href": "posts/Penguins/index.html#exploring-culmen-features-in-relation-to-flipper-lenght",
    "title": "Classifying Palmer Penguins",
    "section": "Exploring Culmen Features in relation to Flipper Lenght",
    "text": "Exploring Culmen Features in relation to Flipper Lenght\nThe graph below explores the relationship between flipper length and culmen length across penguin species. Gentoo penguins have both longer flipper lengths and culmen lengths compared to the other species, making them easily distinguishable. Adelie penguins, in contrast, have shorter values for both features, clustering in the lower-left section of the graph. Chinstrap penguins overlap with Adelie penguins in flipper length but tend to have slightly longer culmen lengths, creating some classification challenges.\n\nsns.relplot(data = train, y = 'Culmen Length (mm)', x =  'Flipper Length (mm)',  hue = 'Species').set(title='Relation between Flipper Length and Culmen Length')\n\n\n\n\n\n\n\n\n\n\nsns.relplot(data = train, y = 'Culmen Depth (mm)', x =  'Flipper Length (mm)',  hue = 'Species').set(title='Relation between Flipper Length and Culmen Depth')\n\n\n\n\n\n\n\n\nThe graph above examines the relationship between flipper length and culmen depth. Here, Gentoo penguins are clearly separable from the other two species due to their significantly shallower culmen depths, forming a distinct cluster in the lower section. Howeber the Adelie and Chinstrap penguins overlap a lot more, particularly in flipper length and culmen depth. While Gentoo penguins can be classified easily, distinguishing between Adelie and Chinstrap penguins would be really difficult because of this clustering."
  },
  {
    "objectID": "posts/Penguins/index.html#decision-region-plots",
    "href": "posts/Penguins/index.html#decision-region-plots",
    "title": "Classifying Palmer Penguins",
    "section": "Decision Region Plots",
    "text": "Decision Region Plots\nThis code below helps us visualize the decision regions of our classification model by plotting how different penguin species are separated based on culmen features and island locations. It creates a grid of values for the culmen length and depth, predicts species across the grid. Each subplot represents a different island, showing how the model’s decision boundaries change depending on the island feature. This helps us understand how the model differentiates between Adelie, Chinstrap, and Gentoo penguins on each island.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y, title):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    # Define a color mapping where Gentoo is green and Chinstrap is blue\n    species_colors = {0: 'red', 1: 'blue', 2: 'green'}\n    \n    # Adjust figure size for better visibility\n    fig, axarr = plt.subplots(1, len(qual_features), figsize=(12 * len(qual_features), 10))  # Increase size\n    fig.suptitle(title, fontsize=40, y=1.05)  # Adjust title position and size\n\n    # Create a grid\n    grid_x = np.linspace(x0.min(), x0.max(), 501)\n    grid_y = np.linspace(x1.min(), x1.max(), 501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    if len(qual_features) == 1:\n        axarr = [axarr] \n\n    for i, ax in enumerate(axarr):\n        XY = pd.DataFrame({\n            X.columns[0]: XX,\n            X.columns[1]: YY\n        })\n\n        for j in qual_features:\n            XY[j] = 0\n\n        XY[qual_features[i]] = 1\n\n        p = model.predict(XY)\n        p = p.reshape(xx.shape)\n        \n        # Use contour plot to visualize the predictions\n        ax.contourf(xx, yy, p, cmap=\"jet\", alpha=0.2, vmin=0, vmax=2)\n\n        ix = X[qual_features[i]] == 1\n        # Convert y[ix] to a pandas Series and apply map to get colors\n        y_series = pd.Series(y[ix])  # Convert y[ix] to a Series\n        ax.scatter(x0[ix], x1[ix], c=y_series.map(species_colors), s=80)  # Larger scatter points\n\n        ax.set_xlabel(X.columns[0], fontsize=30)\n        ax.set_ylabel(X.columns[1], fontsize=30)\n        ax.set_title(qual_features[i], fontsize=35)\n\n        ax.tick_params(axis='both', labelsize=25)  # Larger tick labels\n\n    # Increase spacing between subplots and adjust title positioning\n    plt.subplots_adjust(wspace=0.4, hspace=0.3, top=0.85)  \n\n    # Create legend with specific colors for species\n    patches = [Patch(color=color, label=spec) for spec, color in zip([\"Adelie\", \"Chinstrap\", \"Gentoo\"], [\"red\", \"blue\", \"green\"])]\n    fig.legend(handles=patches, title=\"Species\", loc=\"upper right\", fontsize=30, title_fontsize=35, bbox_to_anchor=(1.03, 1)) \n\n    plt.show()\n\n# Run function for training and test sets\nplot_regions(LR, X_train[best_features], y_train, title=\"Training Set\")\nplot_regions(LR, X_test[best_features], y_pred, title=\"Test Set\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe decision region plots clearly show how our model classifies penguins based on culmen length and depth, with island location influencing the boundaries.\n\nIsland Biscoe: The model effectively separates Gentoo (green) from Adelie (red) penguins, as they occupy distinct regions.\nIsland Dream: Chinstrap (blue) and Adelie (red) penguins have overlapping regions, making classification slightly more challenging. However, longer culmen lengths help differentiate Chinstrap penguins.\nIsland Torgersen: Since only Adlie penguins are found here, the entire region is classified as red, confirming that island location alone can sometimes be a strong predictor.\n\nThe clean decision boundaries in most plots indicate that the selected features work really well for our classification."
  },
  {
    "objectID": "posts/Penguins/index.html#discussion-and-takeaways",
    "href": "posts/Penguins/index.html#discussion-and-takeaways",
    "title": "Classifying Palmer Penguins",
    "section": "Discussion And Takeaways",
    "text": "Discussion And Takeaways\nThrough this analysis, I gained several important insights about both the dataset and machine learning model performance. One of the key takeaways was the importance of data preprocessing, including encoding categorical variables and handling missing data, to ensure the model could learn effectively. By visualizing relationships between features, I noticed that certain physical traits, like culmen length and culmen depth, played a crucial role in distinguishing penguin species. Additionally, island location proved to be a strong predictor, as some species were exclusive to certain islands.\nTraining a logistic regression model with carefully selected features led to a 99% accuracy on the training set and 100% accuracy on the test set, showing that the model generalized well to unseen data. The decision region plots clearly illustrated how the model separated species based on their culmen features, with some overlap between Adelie and Chinstrap penguins making classification slightly more challenging. Overall, this project demonstrated how feature selection, visualization, and a well-trained model can achieve highly accurate classifications, reinforcing the power of machine learning in biological research."
  },
  {
    "objectID": "posts/Penguins/index.html#goal-of-project",
    "href": "posts/Penguins/index.html#goal-of-project",
    "title": "Classifying Palmer Penguins",
    "section": "Goal of Project",
    "text": "Goal of Project\nPredicting a penguin’s species based on its physical measurements is an interesting challenge in data analysis and machine learning. In this blog, we’ll explore the Palmer Penguins dataset, which was collected by Dr. Kristen Gorman and the Palmer Station, to analyze biological measurements of three penguin species in Antarctica. Through data visualization and feature selection, we’ll uncover key insights and build a classification model that achieves perfect accuracy using a carefully chosen set of features. Along the way, we’ll discuss our findings and ensure a reproducible and insightful approach to species classification."
  },
  {
    "objectID": "posts/Penguins/index.html#loading-data",
    "href": "posts/Penguins/index.html#loading-data",
    "title": "Classifying Palmer Penguins",
    "section": "Loading Data",
    "text": "Loading Data\nWe will now use the Pandas function to read the CSV and also take a look at the data and the different variables and columns we have in our dataset before we do and data explorations and analysis.\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN"
  },
  {
    "objectID": "posts/Penguins/index.html#abstract",
    "href": "posts/Penguins/index.html#abstract",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "The Palmer Penguins dataset, collected by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, provides physiological measurements for three species of penguins—Adélie, Chinstrap, and Gentoo—inhabiting the Palmer Archipelago. First published in 2014 and later made widely accessible to the data science community, this dataset serves as a valuable resource for exploring classification techniques and species differentiation. In this blog post, I analyze the dataset using machine learning models to classify penguin species based on features such as flipper length, body mass, and culmen dimensions. By analyzing physical measurements we identify key features that contribute to accurate species prediction. Through data visualization and feature selection, we uncover patterns that distinguish species based on island location and physical traits. Using logistic regression, we evaluate different feature combinations and determine an optimal set for classification and acheive a 99% training accuracy and a 100% testing accuracy. Our findings highlight the power of data-driven approaches in biological classification while ensuring a reproducible and insightful methodology."
  },
  {
    "objectID": "posts/Penguins/index.html#visualizing-the-data",
    "href": "posts/Penguins/index.html#visualizing-the-data",
    "title": "Classifying Palmer Penguins",
    "section": "Visualizing the data",
    "text": "Visualizing the data\nThe bar chart below shows the number of penguins of each species on different islands, helping us identify patterns in species distribution. Interestingly, we observe:\n\nTorgersen Island: Only Adelie penguins are present, with a population of about 30-40 individuals.\nDream Island: Has both Adelie and Chinstrap penguins, with Chinstrap being the dominant species.\nBiscoe Island: Has both Adelie and Gentoo penguins, with Gentoo having the largest population overall.\n\nChinstrap penguins are only found on Dream Island, while Gentoo penguins are exclusive to Biscoe Island. Adelie penguins, on the other hand, are the most widespread, appearing on all three islands. Based on this distribution, the island where a penguin is found could be a useful feature for predicting its species.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n# Map species labels back to names\nspecies_map = {0: 'Adelie', 1: 'Chinstrap', 2: 'Gentoo'}\nspecies_island_counts = X_train.copy()\nspecies_island_counts[\"Species\"] = [species_map[label] for label in y_train]\n\n# Convert one-hot encoded islands back to a single column\nspecies_island_counts[\"Island\"] = species_island_counts[[\"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]].idxmax(axis=1)\nspecies_island_counts[\"Island\"] = species_island_counts[\"Island\"].str.replace(\"Island_\", \"\")\n\n# Count number of penguins per species per island\nplot_data = species_island_counts.groupby([\"Island\", \"Species\"]).size().reset_index(name=\"Count\")\n\n# Plot\nplt.figure(figsize=(8, 5))\nsns.barplot(data=plot_data, x=\"Island\", y=\"Count\", hue=\"Species\", palette=\"mako\")\nplt.xlabel(\"Island\")\nplt.ylabel(\"Number of Penguins\")\nplt.title(\"Penguin Species Distribution Across Islands\")\nplt.legend(title=\"Species\")\nplt.show()\n\n\n\n\n\n\n\n\nBased on the graph above, we can see that by simply looking at the islands, we can somewhat predict the species of the penguin. This is a good example of a feature that could help predict the species. However, the model would be much more efficient if each island only hosted one species of penguin. Since some islands have more than one species, we might want to explore additional features. For example, if a penguin is on Biscoe Island and has a certain Culmen length and Culmen depth, can we make more accurate predictions based on those measurements? To explore this, we will create a graph to assess whether including Culmen lenght and Culmen depth is a useful feature for predicting the species on each island.\n\n\n# Plotting the relationship between Culmen Length and Culmen Depth for each species on each island\ng = sns.relplot(data=train, hue=\"Species\", y=\"Culmen Depth (mm)\", x=\"Culmen Length (mm)\", col=\"Island\")\n\ng.set_titles(size=18)  # Increase subplot titles\ng.set_axis_labels(\"Culmen Length (mm)\", \"Culmen Depth (mm)\", fontsize=16)  # Increase axis labels font size\ng._legend.set_title(\"Species\", prop={'size': 16}) \n[g._legend.get_texts()[i].set_fontsize(14) for i in range(len(g._legend.get_texts()))]  # Increase legend text size\n\nplt.show()\n\n\n\n\n\n\n\n\n\nThe graph above looks at the relationship between Culmen Depth (mm) and Culmen Length (mm) for different penguin species, separated by island. Each species is color-coded to highlight patterns in their beak dimensions. From this graph, we can observe:\n\nGentoo penguins (orange) tend to have longer culmen lengths and shallower culmen depths.\nAdelie penguins (green) have moderate culmen lengths and a wide range of culmen depths.\nChinstrap penguins (blue) have longer culmen lenghts compared to Adelie penguins but exhibit similar culmen Depths."
  },
  {
    "objectID": "posts/Penguins/index.html#feature-analysis-flipper-and-culmen-measurements",
    "href": "posts/Penguins/index.html#feature-analysis-flipper-and-culmen-measurements",
    "title": "Classifying Palmer Penguins",
    "section": "Feature Analysis: Flipper and Culmen Measurements",
    "text": "Feature Analysis: Flipper and Culmen Measurements\nThe table below shows the mean values of flipper length, culmen length, and culmen depth for each penguin species using the .groupby() function. The table summarizes the average flipper length, culmen length, and culmen depth for each penguin species. Gentoo penguins have the longest flipper and culmen lengths but the shallowest culmen depth. Chinstrap penguins have longer culmen lengths than Adelie penguins but similar culmen depths. Adelie penguins have the shortest flipper and culmen lengths but slightly deeper culmens than Chinstrap. These differences highlight key features that can help classify penguin species.\n\ntrain.groupby('Species').agg({\n    'Flipper Length (mm)': 'mean',\n    'Culmen Length (mm)': 'mean',\n    'Culmen Depth (mm)': 'mean'\n}).reset_index()\n\n\n\n\n\n\n\n\nSpecies\nFlipper Length (mm)\nCulmen Length (mm)\nCulmen Depth (mm)\n\n\n\n\n0\nAdelie Penguin (Pygoscelis adeliae)\n190.084034\n38.970588\n18.409244\n\n\n1\nChinstrap penguin (Pygoscelis antarctica)\n196.000000\n48.826316\n18.366667\n\n\n2\nGentoo penguin (Pygoscelis papua)\n216.752577\n47.073196\n14.914433"
  },
  {
    "objectID": "posts/Penguins/index.html#lets-now-prepare-our-test-dataset",
    "href": "posts/Penguins/index.html#lets-now-prepare-our-test-dataset",
    "title": "Classifying Palmer Penguins",
    "section": "Let’s now prepare our Test Dataset",
    "text": "Let’s now prepare our Test Dataset\n\n# Load test data\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\n# Prepare test data\nX_test, y_test = prepare_data(test)"
  },
  {
    "objectID": "posts/Penguins/index.html#now-we-are-going-to-chose-features-to-train-our-model",
    "href": "posts/Penguins/index.html#now-we-are-going-to-chose-features-to-train-our-model",
    "title": "Classifying Palmer Penguins",
    "section": "Now we are going to chose features to train our model",
    "text": "Now we are going to chose features to train our model\nBy using the combinations function from the itertools package, we generate different combinations of categorical and continuous features. So we will pair categorical variables like Sex and Clutch Completion with continuous variables such as Culmen Length, Culmen Depth, and Flipper Length. This allows us to explore various feature combinations and evaluate which ones might be most useful for accurately classifying the penguin species.\n\nfrom itertools import combinations\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\n\nbest_score = 0\nbest_features = None\n\nfor qual in all_qual_cols:\n    qual_cols = [col for col in X_train.columns if qual in col]  # Ensure categorical features are one-hot encoded\n    for pair in combinations(all_quant_cols, 2):\n        cols = qual_cols + list(pair)\n        \n        # Train a logistic regression model to evaluate feature combinations\n        model = LogisticRegression(max_iter=1000)  # Increased iterations for better convergence\n        scores = cross_val_score(model, X_train[cols], y_train, cv=5, scoring='accuracy')\n        \n        avg_score = np.mean(scores)\n        if avg_score &gt; best_score:\n            best_score = avg_score\n            best_features = cols\n\nprint(\"Best features:\", best_features)\n\nBest features: ['Sex_FEMALE', 'Sex_MALE', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n\n\nAccording to itertools, the best features to use are ‘Sex_FEMALE’, ‘Sex_MALE’, ‘Culmen Length (mm)’, and ‘Culmen Depth (mm)’. However, we wanted to explore how our model would perform based on our exploration of the island features along with the Culmen features. Thus, we will now reassign these as the best features and use them to train our model.\n\n#Rearranging Best featrues so that the first two columns are the quantitative columns and the rest are the qualitative columns\nbest_features = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\nbest_features\n\n['Culmen Length (mm)',\n 'Culmen Depth (mm)',\n 'Island_Biscoe',\n 'Island_Dream',\n 'Island_Torgersen']"
  },
  {
    "objectID": "posts/new-new-test-post/index.html#loading-the-data",
    "href": "posts/new-new-test-post/index.html#loading-the-data",
    "title": "Classifying Palmer Penguins",
    "section": "Loading the data",
    "text": "Loading the data\n\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf_train = pd.read_csv(url)\n\n\ndf_train.head()\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\n\n\n\n\n0\n25\n43200\nRENT\nNaN\nVENTURE\nB\n1200\n9.91\n0\n0.03\nN\n4\n\n\n1\n27\n98000\nRENT\n3.0\nEDUCATION\nC\n11750\n13.47\n0\n0.12\nY\n6\n\n\n2\n22\n36996\nRENT\n5.0\nEDUCATION\nA\n10000\n7.51\n0\n0.27\nN\n4\n\n\n3\n24\n26000\nRENT\n2.0\nMEDICAL\nC\n1325\n12.87\n1\n0.05\nN\n4\n\n\n4\n29\n53004\nMORTGAGE\n2.0\nHOMEIMPROVEMENT\nA\n15000\n9.63\n0\n0.28\nN\n10"
  },
  {
    "objectID": "posts/new-new-test-post/index.html#abstract-and-methodologies",
    "href": "posts/new-new-test-post/index.html#abstract-and-methodologies",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "Automated decision systems are increasingly used in financial institutions to assess credit risk and determine loan eligibility. In this blog post, we build upon the theoretical framework of binary decision-making with a linear score function, applying it to a more realistic credit-risk prediction scenario. Our goal is twofold: first, to develop a score function and threshold that optimize a bank’s total expected profit while considering various borrower features; and second, to assess how this decision system impacts different demographic segments. By leveraging data-driven modeling, visualization, and profit-based optimization, we aim to create a more informed and equitable approach to automated lending decisions."
  },
  {
    "objectID": "posts/new-new-test-post/index.html#analysis-of-loan-intent-by-age-group",
    "href": "posts/new-new-test-post/index.html#analysis-of-loan-intent-by-age-group",
    "title": "Classifying Palmer Penguins",
    "section": "Analysis of Loan Intent by Age Group",
    "text": "Analysis of Loan Intent by Age Group\nThis bar chart below shows how different age groups use their loans for various purposes—such as venture, education, medical, home improvement, personal, and debt consolidation. We can see that borrowers aged 18–29 make up a large portion of total loans, often driven by education and personal loan needs. As age increases, the number of loans generally decreases, but certain categories—like debt consolidation—can become more common in older groups.\nOverall, this chart highlights that younger borrowers borrow a lot more money may be more focused on educational or personal financing, while older borrowers might shift their attention to consolidating debt or improving their homes. Understanding these patterns help us in understanding different patternns in who would default on a loan and not.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load the data\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf = pd.read_csv(url)\n\n# Create additional features for analysis:\n# 1. Age groups: we create bins to see how loan intent varies with age.\nage_bins = [18, 30, 40, 50, 60, 100]\nage_labels = ['18-29', '30-39', '40-49', '50-59', '60+']\ndf['age_group'] = pd.cut(df['person_age'], bins=age_bins, labels=age_labels)\n\n# ---------------------------\n# Visualization 1:\n# How does loan intent vary with age and home ownership status?\nplt.figure(figsize=(10, 6))\nsns.countplot(data=df, x='age_group', hue='loan_intent')\nplt.title('Loan Intent Distribution by Age Group')\nplt.xlabel('Age Group')\nplt.ylabel('Count')\nplt.legend(title='Loan Intent')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/new-new-test-post/index.html#analysis-of-average-loan-amount-by-credit-history-length",
    "href": "posts/new-new-test-post/index.html#analysis-of-average-loan-amount-by-credit-history-length",
    "title": "Classifying Palmer Penguins",
    "section": "Analysis of Average Loan Amount by Credit History Length",
    "text": "Analysis of Average Loan Amount by Credit History Length\nThis bar chart shows how the average loan amount changes based on the number of years a borrower has had a credit history. In general, we see that some longer lengths of credit history are associated with higher average loan amounts than others, though the pattern isn’t strictly increasing or decreasing. This suggests that lenders may be willing to extend larger lines of credit to individuals with certain credit history profiles.\nFor our automated decision system, credit history length could be an important feature because it often reflects a borrower’s past experience with credit and repayment behavior. However, we must be mindful of fairness and potential biases: borrowers who are younger or newer to credit might be at a disadvantage if the model heavily weighs credit history length. Balancing profitability for the bank with equitable access to credit remains a key challenge in designing our scoring and thresholding methods.\n\n\n# 2. Employment length groups: useful for exploring patterns with job experience.\nemp_bins = [0, 2, 5, 10, df['person_emp_length'].max()]\nemp_labels = ['0-1 yrs', '2-4 yrs', '5-9 yrs', '10+ yrs']\ndf['emp_length_group'] = pd.cut(df['person_emp_length'], bins=emp_bins, labels=emp_labels)\n\n# ---------------------------\n# Visualization 2:\n# Which segments are offered different interest rates? Compare distributions by home ownership.\nplt.figure(figsize=(10, 6))\navg_loan = df.groupby('cb_person_cred_hist_length')['loan_amnt'].mean().reset_index()\nsns.barplot(data=avg_loan, x='cb_person_cred_hist_length', y='loan_amnt')\nplt.title('Average Loan Amount by Credit History Length')\nplt.xlabel('Credit History Length (Years)')\nplt.ylabel('Average Loan Amount')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/new-new-test-post/index.html#analysis-of-loan-amount-vs.-loan-of-income-by-home-ownership",
    "href": "posts/new-new-test-post/index.html#analysis-of-loan-amount-vs.-loan-of-income-by-home-ownership",
    "title": "Classifying Palmer Penguins",
    "section": "Analysis of Loan Amount vs. Loan % of Income by Home Ownership",
    "text": "Analysis of Loan Amount vs. Loan % of Income by Home Ownership\nIn our scatter plot below, each dot represents a borrower, with the x-axis showing how large the loan is relative to their income (as a percentage) and the y-axis showing the absolute loan amount. The colors indicate different types of home ownership (RENT, MORTGAGE, OWN, OTHER).\nAs you can see, the data points overlap heavily, making the chart look cluttered. To get a clearer picture, I wo;; split these data into separate graphs for each home ownership category. This will help us see more nuanced patterns—like whether renters tend to have higher loan-to-income ratios compared to those who own or have a mortgage.\n\nplt.figure(figsize=(10, 6))\nsns.scatterplot(\n    data=df, \n    x='loan_percent_income_pct', \n    y='loan_amnt', \n    hue='person_home_ownership',\n    alpha=0.7\n)\nplt.title('Loan Amount vs. Loan % of Income by Home Ownership')\nplt.xlabel('Loan as % of Person Income')\nplt.ylabel('Loan Amount')\nplt.xlim(0, 100)  # Focus on 0–100% if most loans fall in this range\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/new-new-test-post/index.html#analysis-of-loan-amount-vs.-loan-of-income-by-home-ownership-separated-plots",
    "href": "posts/new-new-test-post/index.html#analysis-of-loan-amount-vs.-loan-of-income-by-home-ownership-separated-plots",
    "title": "Classifying Palmer Penguins",
    "section": "Analysis of Loan Amount vs. Loan % of Income by Home Ownership (Separated Plots)",
    "text": "Analysis of Loan Amount vs. Loan % of Income by Home Ownership (Separated Plots)\nBy splitting the data into four subplots (one for each home ownership category), we can see that:\n\nRenters typically have loan amounts averaging around $10,000–$12,000, with a wide spread of loan-to-income ratios (averaging around 15–20%). In addition to this we see the most clustering for this group which means, in our dataset most of the people taking our loans are from this group.\nMortgage holders often take out larger loans (averaging $16,000–$18,000) but may have lower loan-to-income ratios (closer to 10% on average).\nOwners (those who fully own their homes) tend to borrow moderate amounts ($12,000–$15,000) at ratios of around 12–15%.\nOthers (less common categories) show a broad mix but generally fall between these ranges.\n\nThese distinctions are important for our automated decision system, since each home ownership group presents a different risk and borrowing profile. When designing a score function and threshold to maximize the bank’s profit, it’s important for us to consider whether certain groups (like renters) might be unfairly penalized if they tend to have higher loan-to-income ratios. Ultimately, these separate plots help us fine-tune our model so that we balance profitability with equitable access to credit across different segments of borrowers.\n\ndf['loan_percent_income_pct'] = df['loan_percent_income'] * 100\n\n# Create a FacetGrid: one subplot per home ownership category\ng = sns.FacetGrid(df, col=\"person_home_ownership\", col_wrap=2, height=4)\ng.map(sns.scatterplot, \"loan_percent_income_pct\", \"loan_amnt\", alpha=0.7)\n\n# Set the x-axis limits and labels for clarity\ng.set(xlim=(0, 100))\ng.set_axis_labels(\"Loan as % of Income\", \"Loan Amount\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/new-new-test-post/index.html#summary-of-loan-intent-and-home-ownership-segments",
    "href": "posts/new-new-test-post/index.html#summary-of-loan-intent-and-home-ownership-segments",
    "title": "Classifying Palmer Penguins",
    "section": "Summary of Loan Intent and Home Ownership Segments",
    "text": "Summary of Loan Intent and Home Ownership Segments\nThis table shows how different combinations of loan intent (e.g., EDUCATION, MEDICAL, PERSONAL) and home ownership (MORTGAGE, OWN, RENT, OTHER) compare in terms of average interest rate, average loan amount, and count of borrowers. We’ve sorted the table by average loan amount in descending order to identify which segments receive the largest lines of credit.\n\nHighest Averages: Segments like PERSONAL–OTHER and MEDICAL–OTHER appear near the top, suggesting they receive higher loan amounts (over $12,000 on average), but also tend to have higher interest rates (11–12%).\nMortgage vs. Rent: Many MORTGAGE segments (e.g., DEBTCONSOLIDATION–MORTGAGE, EDUCATION–MORTGAGE) cluster in the middle, with average loan amounts around $10,000–$11,000 and interest rates near 10–10.6%. Renters often see slightly higher interest rates (11–12%) and somewhat lower loan amounts (around $8,000–$9,000).\nLow Counts: Some segments have very few borrowers (like DEBTCONSOLIDATION–OWN with a count of only 62), which may not be reliable for broad conclusions.\n\nFrom the perspective of building an automated decision system, these patterns hint at where the bank’s profit opportunities and risks might lie. For instance, segments with higher average loan amounts but also higher interest rates could be more profitable—but might also carry greater default risk. Tracking how many borrowers fall into each segment (the “count” column) helps ensure the model doesn’t overly focus on small, potentially unrepresentative groups.\n\nsummary_table = (\n    df\n    .groupby(['loan_intent', 'person_home_ownership'], as_index=False)\n    .agg(\n        avg_interest_rate=('loan_int_rate', 'mean'),\n        avg_loan_amount=('loan_amnt', 'mean'),\n        count=('loan_amnt', 'count')  # how many borrowers in each segment\n    )\n)\n\n# Sort by average loan amount (descending) to see which segments get the largest lines of credit\nsummary_table_sorted_by_amount = summary_table.sort_values('avg_loan_amount', ascending=False)\n\nsummary_table_sorted_by_amount\n\n\n\n\n\n\n\n\n\nloan_intent\nperson_home_ownership\navg_interest_rate\navg_loan_amount\ncount\n\n\n\n\n17\nPERSONAL\nOTHER\n11.675714\n12366.666667\n15\n\n\n13\nMEDICAL\nOTHER\n12.745000\n12200.000000\n13\n\n\n5\nEDUCATION\nOTHER\n12.400833\n12142.857143\n14\n\n\n9\nHOMEIMPROVEMENT\nOTHER\n11.683000\n10959.090909\n11\n\n\n8\nHOMEIMPROVEMENT\nMORTGAGE\n10.613916\n10764.017341\n1384\n\n\n20\nVENTURE\nMORTGAGE\n10.468000\n10606.281060\n1811\n\n\n0\nDEBTCONSOLIDATION\nMORTGAGE\n10.400489\n10588.756111\n1841\n\n\n4\nEDUCATION\nMORTGAGE\n10.554563\n10502.178076\n2089\n\n\n12\nMEDICAL\nMORTGAGE\n10.505553\n10485.867052\n1730\n\n\n16\nPERSONAL\nMORTGAGE\n10.426285\n10481.223233\n1868\n\n\n21\nVENTURE\nOTHER\n12.274211\n10367.500000\n20\n\n\n11\nHOMEIMPROVEMENT\nRENT\n11.812287\n10109.604633\n1252\n\n\n1\nDEBTCONSOLIDATION\nOTHER\n11.566667\n9783.333333\n15\n\n\n14\nMEDICAL\nOWN\n10.749097\n9367.755682\n352\n\n\n10\nHOMEIMPROVEMENT\nOWN\n10.922405\n9242.450980\n255\n\n\n6\nEDUCATION\nOWN\n10.797507\n8996.177184\n412\n\n\n18\nPERSONAL\nOWN\n10.867262\n8944.209040\n354\n\n\n3\nDEBTCONSOLIDATION\nRENT\n11.358223\n8882.754425\n2260\n\n\n19\nPERSONAL\nRENT\n11.535415\n8826.900046\n2171\n\n\n23\nVENTURE\nRENT\n11.438455\n8804.566745\n2135\n\n\n22\nVENTURE\nOWN\n10.560000\n8789.621914\n648\n\n\n7\nEDUCATION\nRENT\n11.315216\n8685.308193\n2612\n\n\n15\nMEDICAL\nRENT\n11.422580\n8426.925182\n2740\n\n\n2\nDEBTCONSOLIDATION\nOWN\n14.432909\n7749.193548\n62"
  },
  {
    "objectID": "posts/new-new-test-post/index.html#training-and-evaluating-our-logistic-regression-model",
    "href": "posts/new-new-test-post/index.html#training-and-evaluating-our-logistic-regression-model",
    "title": "Classifying Palmer Penguins",
    "section": "Training and evaluating our Logistic Regression model",
    "text": "Training and evaluating our Logistic Regression model\nI used a logistic regression model to predict whether a prospective borrower will default on a loan. After preprocessing the data—by standardizing numerical features and one-hot encoding categorical variables. I removed rows with missing values, and split the dataset into training and test sets. The model achieved a test accuracy of about 84.2%.\nThe confusion matrix provides additional insight into the model’s performance:\n\nTrue Negatives (TN): 3,393 borrowers who did not default and were correctly predicted as non-default.\nFalse Positives (FP): 221 borrowers who did not default but were incorrectly flagged as defaults.\nFalse Negatives (FN): 501 borrowers who defaulted but were missed by the model.\nTrue Positives (TP): 467 borrowers who defaulted and were correctly identified.\n\nOur results suggest that while the model performs reasonably well overall, there is still a balance to be struck between avoiding false positives and false negatives. This is particularly important when designing an automated decision system for credit risk, because both profitability for the bank and equitable access to credit are critical. Further tuning of the threshold and exploration of additional features could help optimize the model even further for its intended purpose\n\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Drop rows with missing values\ndf_train = df_train.dropna(subset=numeric_features + categorical_features)\n\n\ntarget = 'loan_status'\nX = df_train.drop(columns=[target])\ny = df_train[target]\n\nnumeric_features = ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', \n                      'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length']\ncategorical_features = ['person_home_ownership', 'loan_intent', 'cb_person_default_on_file']\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), numeric_features),\n        ('cat', OneHotEncoder(drop='first'), categorical_features)\n    ])\nX_transformed = preprocessor.fit_transform(X)\n\n# Split the transformed data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X_transformed, y, test_size=0.2, random_state=123\n)\n\n# Fit a logistic regression model using the preprocessed features\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\n\nprint(\"Test Accuracy:\", accuracy)\nprint(\"Confusion Matrix:\\n\", conf_matrix)\n\nTest Accuracy: 0.8424268878219118\nConfusion Matrix:\n [[3393  221]\n [ 501  467]]"
  },
  {
    "objectID": "posts/new-new-test-post/index.html#finding-weight-and-threshold",
    "href": "posts/new-new-test-post/index.html#finding-weight-and-threshold",
    "title": "Classifying Palmer Penguins",
    "section": "Finding weight and threshold",
    "text": "Finding weight and threshold\n\n# ------------------------------------------------------\n# 1. Define the profit formulas (vectorized)\n# ------------------------------------------------------\ndef profit_if_repaid(loan_amnt, loan_int_rate):\n    \"\"\"\n    If the loan is repaid in full, the bank's profit is:\n      loan_amnt * (1 + 0.25*loan_int_rate)^10 - loan_amnt\n    \"\"\"\n    return loan_amnt * (1 + 0.25 * loan_int_rate) ** 10 - loan_amnt\n\ndef profit_if_default(loan_amnt, loan_int_rate):\n    \"\"\"\n    If the borrower defaults, we assume default happens 3 years into the loan, \n    and the bank loses 70% of the principal:\n      loan_amnt*(1 + 0.25*loan_int_rate)^3 - 1.7*loan_amnt\n    \"\"\"\n    return loan_amnt * (1 + 0.25 * loan_int_rate) ** 3 - 1.7 * loan_amnt\n\nWe will now compute predicted probabilities (probability of default) for the training data\n\ny_prob_train = model.predict_proba(X_train)[:, 1]  # column 1 = probability of default\n\n\n# Split the transformed data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=123\n)\nloan_amnt_array = X_train['loan_amnt'].to_numpy()\nloan_int_rate_array = X_train['loan_int_rate'].to_numpy()\ny_train_array = y_train.to_numpy()\nprofit_repaid = profit_if_repaid(loan_amnt_array, loan_int_rate_array)\nprofit_default = profit_if_default(loan_amnt_array, loan_int_rate_array)\n\nNow we are going to find a threshold and identify teh best threshold\n\n# 5. Sweep over thresholds to find the one that maximizes average profit\n\nthresholds = np.linspace(0, 1, 101)\navg_profits = []\n\nfor t in thresholds:\n    # Predict default if probability &gt;= t\n    predicted_default = (y_prob_train &gt;= t).astype(int)\n      # If we predict default, we do NOT give the loan =&gt; profit = 0\n    # If we predict no default, we DO give the loan =&gt; actual profit depends on y_train_array\n    #    - If actual y=0 (no default), profit = profit_repaid\n    #    - If actual y=1 (default), profit = profit_default\n    give_loan = 1 - predicted_default  # 1 = give loan, 0 = no loan\n    # total_profit[i] = give_loan[i] * [ (1 - y[i])*profit_repaid[i] + y[i]*profit_default[i] ]\n    total_profit = give_loan * ((1 - y_train_array) * profit_repaid + y_train_array * profit_default)\n    \n    # Compute average profit per borrower\n    avg_profit = total_profit.mean()\n    avg_profits.append(avg_profit)\n\navg_profits = np.array(avg_profits)\n\n# 6. Identify the best threshold\n\nbest_idx = np.argmax(avg_profits) # index of the best threshold\nbest_threshold = thresholds[best_idx]\n\n\nprint(f\"Best Threshold: {best_threshold:.3f}\")\n\nBest Threshold: 1.000\n\n\n\n# 7. Plot profit vs. threshold\n\nplt.figure(figsize=(8, 5))\nplt.plot(thresholds, avg_profits, label='Profit per Borrower')\nplt.scatter(best_threshold, best_profit, color='red', zorder=10, label='Optimal Threshold')\nplt.title('Profit per Borrower (Training Set) vs. Threshold')\nplt.xlabel('Threshold (Probability of Default)')\nplt.ylabel('Average Profit per Borrower')\nplt.legend()\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/discecting_racial_bias_algo/index.html",
    "href": "posts/discecting_racial_bias_algo/index.html",
    "title": "Dissecting racial bias in an algorithm used to manage the health of populations",
    "section": "",
    "text": "In this project, I aim to replicate and extend the findings of Obermeyer et al. (2019) by exploring how healthcare cost predictions relate to patients’ chronic illness burden and race. Using a randomized dataset, we first visualize the relationship between risk score percentiles, chronic conditions, and medical expenditures, revealing that White patients tend to generate higher costs than Black patients despite similar illness burdens. We then built a Ridge regression model with polynomial features to quantify the disparity in costs between Black and White patients. Our final model estimates that, holding illness burden constant, Black patients incur roughly 81% of the costs incurred by White patients, suggesting that the cost-based risk score underestimates the true care needs of Black patients."
  },
  {
    "objectID": "posts/discecting_racial_bias_algo/index.html#exporing-the-data",
    "href": "posts/discecting_racial_bias_algo/index.html#exporing-the-data",
    "title": "Dissecting racial bias in an algorithm used to manage the health of populations",
    "section": "",
    "text": "Below we will accesss teh data clean it and explore the different variables and features.\n\nimport pandas as pd\nurl = \"https://gitlab.com/labsysmed/dissecting-bias/-/raw/master/data/data_new.csv?inline=false\"\ndf = pd.read_csv(url)\n# df.dropna(inplace=True)\ndf.head()\n\n\n\n\n\n\n\n\nrisk_score_t\nprogram_enrolled_t\ncost_t\ncost_avoidable_t\nbps_mean_t\nghba1c_mean_t\nhct_mean_t\ncre_mean_t\nldl_mean_t\nrace\n...\ntrig_min-high_tm1\ntrig_min-normal_tm1\ntrig_mean-low_tm1\ntrig_mean-high_tm1\ntrig_mean-normal_tm1\ntrig_max-low_tm1\ntrig_max-high_tm1\ntrig_max-normal_tm1\ngagne_sum_tm1\ngagne_sum_t\n\n\n\n\n0\n1.987430\n0\n1200.0\n0.0\nNaN\n5.4\nNaN\n1.110000\n194.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n7.677934\n0\n2600.0\n0.0\n119.0\n5.5\n40.4\n0.860000\n93.0\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n4\n3\n\n\n2\n0.407678\n0\n500.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0.798369\n0\n1300.0\n0.0\n117.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n17.513165\n0\n1100.0\n0.0\n116.0\nNaN\n34.1\n1.303333\n53.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n\n\n\n\n5 rows × 160 columns\n\n\n\n\nrace_counts_bf_clean = df['race'].value_counts()\ndf.dropna(inplace=True)\nrace_counts = df['race'].value_counts()\nprint(\"Count of patients by race before cleaning data\",race_counts_bf_clean)\nprint(\"Count of patients by race after cleaning data\", race_counts)\n\nCount of patients by race before cleaning data race\nwhite    43202\nblack     5582\nName: count, dtype: int64\nCount of patients by race after cleaning data race\nwhite    5911\nblack    1000\nName: count, dtype: int64\n\n\n\nimport  matplotlib.pyplot as plt\n# Graph 1: Bar chart of race counts\nplt.figure(figsize=(6, 4))\nplt.bar(race_counts.index, race_counts.values, color=['blue', 'orange'])\nplt.xlabel('Race')\nplt.ylabel('Number of Patients')\nplt.title('Number of Black vs. White Patients')\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=df, x=\"risk_score_t\", y=\"cost_t\", hue=\"race\", alpha=0.7)\n\n# Labels and title\nplt.xlabel(\"Risk Score\")\nplt.ylabel(\"Cost\")\nplt.title(\"Risk Score vs Cost by Race\")\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "posts/linear_score_function-Banks/index.html",
    "href": "posts/linear_score_function-Banks/index.html",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "",
    "text": "Automated decision systems are increasingly used in financial institutions to assess credit risk and determine loan eligibility. In this blog post, we build upon the theoretical framework of binary decision-making with a linear score function, applying it to a more realistic credit-risk prediction scenario. Our goal is twofold: first, to develop a score function and threshold that optimize a bank’s total expected profit while considering various borrower features; and second, to assess how this decision system impacts different demographic segments. By leveraging data-driven modeling, visualization, and profit-based optimization, we aim to create a more informed and equitable approach to automated lending decisions."
  },
  {
    "objectID": "posts/linear_score_function-Banks/index.html#abstract-and-methodologies",
    "href": "posts/linear_score_function-Banks/index.html#abstract-and-methodologies",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "",
    "text": "Automated decision systems are increasingly used in financial institutions to assess credit risk and determine loan eligibility. In this blog post, we build upon the theoretical framework of binary decision-making with a linear score function, applying it to a more realistic credit-risk prediction scenario. Our goal is twofold: first, to develop a score function and threshold that optimize a bank’s total expected profit while considering various borrower features; and second, to assess how this decision system impacts different demographic segments. By leveraging data-driven modeling, visualization, and profit-based optimization, we aim to create a more informed and equitable approach to automated lending decisions."
  },
  {
    "objectID": "posts/linear_score_function-Banks/index.html#loading-the-data",
    "href": "posts/linear_score_function-Banks/index.html#loading-the-data",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Loading the data",
    "text": "Loading the data\n\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf_train = pd.read_csv(url)\n\n\ndf_train.head()\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\n\n\n\n\n0\n25\n43200\nRENT\nNaN\nVENTURE\nB\n1200\n9.91\n0\n0.03\nN\n4\n\n\n1\n27\n98000\nRENT\n3.0\nEDUCATION\nC\n11750\n13.47\n0\n0.12\nY\n6\n\n\n2\n22\n36996\nRENT\n5.0\nEDUCATION\nA\n10000\n7.51\n0\n0.27\nN\n4\n\n\n3\n24\n26000\nRENT\n2.0\nMEDICAL\nC\n1325\n12.87\n1\n0.05\nN\n4\n\n\n4\n29\n53004\nMORTGAGE\n2.0\nHOMEIMPROVEMENT\nA\n15000\n9.63\n0\n0.28\nN\n10"
  },
  {
    "objectID": "posts/linear_score_function-Banks/index.html#analysis-of-loan-intent-by-age-group",
    "href": "posts/linear_score_function-Banks/index.html#analysis-of-loan-intent-by-age-group",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Analysis of Loan Intent by Age Group",
    "text": "Analysis of Loan Intent by Age Group\nThis bar chart below shows how different age groups use their loans for various purposes—such as venture, education, medical, home improvement, personal, and debt consolidation. We can see that borrowers aged 18–29 make up a large portion of total loans, often driven by education and personal loan needs. As age increases, the number of loans generally decreases, but certain categories—like debt consolidation—can become more common in older groups.\nOverall, this chart highlights that younger borrowers borrow a lot more money may be more focused on educational or personal financing, while older borrowers might shift their attention to consolidating debt or improving their homes. Understanding these patterns help us in understanding different patternns in who would default on a loan and not.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load the data\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf = pd.read_csv(url)\n\n# Create additional features for analysis:\n# 1. Age groups: we create bins to see how loan intent varies with age.\nage_bins = [18, 30, 40, 50, 60, 100]\nage_labels = ['18-29', '30-39', '40-49', '50-59', '60+']\ndf['age_group'] = pd.cut(df['person_age'], bins=age_bins, labels=age_labels)\n\n# ---------------------------\n# Visualization 1:\n# How does loan intent vary with age and home ownership status?\nplt.figure(figsize=(10, 6))\nsns.countplot(data=df, x='age_group', hue='loan_intent')\nplt.title('Loan Intent Distribution by Age Group')\nplt.xlabel('Age Group')\nplt.ylabel('Count')\nplt.legend(title='Loan Intent')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/linear_score_function-Banks/index.html#analysis-of-average-loan-amount-by-credit-history-length",
    "href": "posts/linear_score_function-Banks/index.html#analysis-of-average-loan-amount-by-credit-history-length",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Analysis of Average Loan Amount by Credit History Length",
    "text": "Analysis of Average Loan Amount by Credit History Length\nThis bar chart shows how the average loan amount changes based on the number of years a borrower has had a credit history. In general, we see that some longer lengths of credit history are associated with higher average loan amounts than others, though the pattern isn’t strictly increasing or decreasing. This suggests that lenders may be willing to extend larger lines of credit to individuals with certain credit history profiles.\nFor our automated decision system, credit history length could be an important feature because it often reflects a borrower’s past experience with credit and repayment behavior. However, we must be mindful of fairness and potential biases: borrowers who are younger or newer to credit might be at a disadvantage if the model heavily weighs credit history length. Balancing profitability for the bank with equitable access to credit remains a key challenge in designing our scoring and thresholding methods.\n\n\n# 2. Employment length groups: useful for exploring patterns with job experience.\nemp_bins = [0, 2, 5, 10, df['person_emp_length'].max()]\nemp_labels = ['0-1 yrs', '2-4 yrs', '5-9 yrs', '10+ yrs']\ndf['emp_length_group'] = pd.cut(df['person_emp_length'], bins=emp_bins, labels=emp_labels)\n\n# ---------------------------\n# Visualization 2:\n# Which segments are offered different interest rates? Compare distributions by home ownership.\nplt.figure(figsize=(10, 6))\navg_loan = df.groupby('cb_person_cred_hist_length')['loan_amnt'].mean().reset_index()\nsns.barplot(data=avg_loan, x='cb_person_cred_hist_length', y='loan_amnt')\nplt.title('Average Loan Amount by Credit History Length')\nplt.xlabel('Credit History Length (Years)')\nplt.ylabel('Average Loan Amount')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/linear_score_function-Banks/index.html#analysis-of-loan-amount-vs.-loan-of-income-by-home-ownership",
    "href": "posts/linear_score_function-Banks/index.html#analysis-of-loan-amount-vs.-loan-of-income-by-home-ownership",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Analysis of Loan Amount vs. Loan % of Income by Home Ownership",
    "text": "Analysis of Loan Amount vs. Loan % of Income by Home Ownership\nIn our scatter plot below, each dot represents a borrower, with the x-axis showing how large the loan is relative to their income (as a percentage) and the y-axis showing the absolute loan amount. The colors indicate different types of home ownership (RENT, MORTGAGE, OWN, OTHER).\nAs you can see, the data points overlap heavily, making the chart look cluttered. To get a clearer picture, I wo;; split these data into separate graphs for each home ownership category. This will help us see more nuanced patterns—like whether renters tend to have higher loan-to-income ratios compared to those who own or have a mortgage.\n\ndf['loan_percent_income_pct'] = df['loan_percent_income'] * 100\nplt.figure(figsize=(10, 6))\nsns.scatterplot(\n    data=df, \n    x='loan_percent_income_pct', \n    y='loan_amnt', \n    hue='person_home_ownership',\n    alpha=0.7\n)\nplt.title('Loan Amount vs. Loan % of Income by Home Ownership')\nplt.xlabel('Loan as % of Person Income')\nplt.ylabel('Loan Amount')\nplt.xlim(0, 100)  # Focus on 0–100% if most loans fall in this range\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/linear_score_function-Banks/index.html#analysis-of-loan-amount-vs.-loan-of-income-by-home-ownership-separated-plots",
    "href": "posts/linear_score_function-Banks/index.html#analysis-of-loan-amount-vs.-loan-of-income-by-home-ownership-separated-plots",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Analysis of Loan Amount vs. Loan % of Income by Home Ownership (Separated Plots)",
    "text": "Analysis of Loan Amount vs. Loan % of Income by Home Ownership (Separated Plots)\nBy splitting the data into four subplots (one for each home ownership category), we can see that:\n\nRenters typically have loan amounts averaging around $10,000–$12,000, with a wide spread of loan-to-income ratios (averaging around 15–20%). In addition to this we see the most clustering for this group which means, in our dataset most of the people taking our loans are from this group.\nMortgage holders often take out larger loans (averaging $16,000–$18,000) but may have lower loan-to-income ratios (closer to 10% on average).\nOwners (those who fully own their homes) tend to borrow moderate amounts ($12,000–$15,000) at ratios of around 12–15%.\nOthers (less common categories) show a broad mix but generally fall between these ranges.\n\nThese distinctions are important for our automated decision system, since each home ownership group presents a different risk and borrowing profile. When designing a score function and threshold to maximize the bank’s profit, it’s important for us to consider whether certain groups (like renters) might be unfairly penalized if they tend to have higher loan-to-income ratios. Ultimately, these separate plots help us fine-tune our model so that we balance profitability with equitable access to credit across different segments of borrowers.\n\n\n\n# Create a FacetGrid: one subplot per home ownership category\ng = sns.FacetGrid(df, col=\"person_home_ownership\", col_wrap=2, height=4)\ng.map(sns.scatterplot, \"loan_percent_income_pct\", \"loan_amnt\", alpha=0.7)\n\n# Set the x-axis limits and labels for clarity\ng.set(xlim=(0, 100))\ng.set_axis_labels(\"Loan as % of Income\", \"Loan Amount\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/linear_score_function-Banks/index.html#summary-of-loan-intent-and-home-ownership-segments",
    "href": "posts/linear_score_function-Banks/index.html#summary-of-loan-intent-and-home-ownership-segments",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Summary of Loan Intent and Home Ownership Segments",
    "text": "Summary of Loan Intent and Home Ownership Segments\nThis table shows how different combinations of loan intent (e.g., EDUCATION, MEDICAL, PERSONAL) and home ownership (MORTGAGE, OWN, RENT, OTHER) compare in terms of average interest rate, average loan amount, and count of borrowers. We’ve sorted the table by average loan amount in descending order to identify which segments receive the largest lines of credit.\n\nHighest Averages: Segments like PERSONAL–OTHER and MEDICAL–OTHER appear near the top, suggesting they receive higher loan amounts (over $12,000 on average), but also tend to have higher interest rates (11–12%).\nMortgage vs. Rent: Many MORTGAGE segments (e.g., DEBTCONSOLIDATION–MORTGAGE, EDUCATION–MORTGAGE) cluster in the middle, with average loan amounts around $10,000–$11,000 and interest rates near 10–10.6%. Renters often see slightly higher interest rates (11–12%) and somewhat lower loan amounts (around $8,000–$9,000).\nLow Counts: Some segments have very few borrowers (like DEBTCONSOLIDATION–OWN with a count of only 62), which may not be reliable for broad conclusions.\n\nFrom the perspective of building an automated decision system, these patterns hint at where the bank’s profit opportunities and risks might lie. For instance, segments with higher average loan amounts but also higher interest rates could be more profitable—but might also carry greater default risk. Tracking how many borrowers fall into each segment (the “count” column) helps ensure the model doesn’t overly focus on small, potentially unrepresentative groups.\n\nsummary_table = (\n    df\n    .groupby(['loan_intent', 'person_home_ownership'], as_index=False)\n    .agg(\n        avg_interest_rate=('loan_int_rate', 'mean'),\n        avg_loan_amount=('loan_amnt', 'mean'),\n        count=('loan_amnt', 'count')  # how many borrowers in each segment\n    )\n)\n\n# Sort by average loan amount (descending) to see which segments get the largest lines of credit\nsummary_table_sorted_by_amount = summary_table.sort_values('avg_loan_amount', ascending=False)\n\nsummary_table_sorted_by_amount\n\n\n\n\n\n\n\n\n\nloan_intent\nperson_home_ownership\navg_interest_rate\navg_loan_amount\ncount\n\n\n\n\n17\nPERSONAL\nOTHER\n11.675714\n12366.666667\n15\n\n\n13\nMEDICAL\nOTHER\n12.745000\n12200.000000\n13\n\n\n5\nEDUCATION\nOTHER\n12.400833\n12142.857143\n14\n\n\n9\nHOMEIMPROVEMENT\nOTHER\n11.683000\n10959.090909\n11\n\n\n8\nHOMEIMPROVEMENT\nMORTGAGE\n10.613916\n10764.017341\n1384\n\n\n20\nVENTURE\nMORTGAGE\n10.468000\n10606.281060\n1811\n\n\n0\nDEBTCONSOLIDATION\nMORTGAGE\n10.400489\n10588.756111\n1841\n\n\n4\nEDUCATION\nMORTGAGE\n10.554563\n10502.178076\n2089\n\n\n12\nMEDICAL\nMORTGAGE\n10.505553\n10485.867052\n1730\n\n\n16\nPERSONAL\nMORTGAGE\n10.426285\n10481.223233\n1868\n\n\n21\nVENTURE\nOTHER\n12.274211\n10367.500000\n20\n\n\n11\nHOMEIMPROVEMENT\nRENT\n11.812287\n10109.604633\n1252\n\n\n1\nDEBTCONSOLIDATION\nOTHER\n11.566667\n9783.333333\n15\n\n\n14\nMEDICAL\nOWN\n10.749097\n9367.755682\n352\n\n\n10\nHOMEIMPROVEMENT\nOWN\n10.922405\n9242.450980\n255\n\n\n6\nEDUCATION\nOWN\n10.797507\n8996.177184\n412\n\n\n18\nPERSONAL\nOWN\n10.867262\n8944.209040\n354\n\n\n3\nDEBTCONSOLIDATION\nRENT\n11.358223\n8882.754425\n2260\n\n\n19\nPERSONAL\nRENT\n11.535415\n8826.900046\n2171\n\n\n23\nVENTURE\nRENT\n11.438455\n8804.566745\n2135\n\n\n22\nVENTURE\nOWN\n10.560000\n8789.621914\n648\n\n\n7\nEDUCATION\nRENT\n11.315216\n8685.308193\n2612\n\n\n15\nMEDICAL\nRENT\n11.422580\n8426.925182\n2740\n\n\n2\nDEBTCONSOLIDATION\nOWN\n14.432909\n7749.193548\n62"
  },
  {
    "objectID": "posts/linear_score_function-Banks/index.html#training-and-evaluating-our-logistic-regression-model",
    "href": "posts/linear_score_function-Banks/index.html#training-and-evaluating-our-logistic-regression-model",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Training and evaluating our Logistic Regression model",
    "text": "Training and evaluating our Logistic Regression model\nI used a logistic regression model to predict whether a prospective borrower will default on a loan. After preprocessing the data—by standardizing numerical features and one-hot encoding categorical variables. I removed rows with missing values, and split the dataset into training and test sets. The model achieved a test accuracy of about 84.2%.\nThe confusion matrix provides additional insight into the model’s performance:\n\nTrue Negatives (TN): 3,393 borrowers who did not default and were correctly predicted as non-default.\nFalse Positives (FP): 221 borrowers who did not default but were incorrectly flagged as defaults.\nFalse Negatives (FN): 501 borrowers who defaulted but were missed by the model.\nTrue Positives (TP): 467 borrowers who defaulted and were correctly identified.\n\nOur results suggest that while the model performs reasonably well overall, there is still a balance to be struck between avoiding false positives and false negatives. This is particularly important when designing an automated decision system for credit risk, because both profitability for the bank and equitable access to credit are critical. Further tuning of the threshold and exploration of additional features could help optimize the model even further for its intended purpose\n\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Drop rows with missing values\ndf_train = df_train.dropna(subset=numeric_features + categorical_features)\n\n\n\n\ntarget = 'loan_status'\nX = df_train.drop(columns=[target])\ny = df_train[target]\n\nnumeric_features = ['person_age', 'person_income', 'person_emp_length', 'loan_amnt', \n                      'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length']\ncategorical_features = ['person_home_ownership', 'loan_intent', 'cb_person_default_on_file']\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), numeric_features),\n        ('cat', OneHotEncoder(drop='first'), categorical_features)\n    ])\nX_transformed = preprocessor.fit_transform(X)\n\n# Split the transformed data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X_transformed, y, test_size=0.2, random_state=123\n)\n\n# Fit a logistic regression model using the preprocessed features\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\n\nprint(\"Test Accuracy:\", accuracy)\nprint(\"Confusion Matrix:\\n\", conf_matrix)\n\nTest Accuracy: 0.8424268878219118\nConfusion Matrix:\n [[3393  221]\n [ 501  467]]"
  },
  {
    "objectID": "posts/linear_score_function-Banks/index.html#finding-weight-and-threshold",
    "href": "posts/linear_score_function-Banks/index.html#finding-weight-and-threshold",
    "title": "Design and Impact of Automated Decision Systems",
    "section": "Finding weight and threshold",
    "text": "Finding weight and threshold\n\ndf['loan_int_rate_decimal'] = df['loan_int_rate'] / 100.0\n\ndef profit_if_repaid(loan_amnt, loan_int_rate_decimal):\n    \"\"\"\n    If the loan is repaid in full, the bank's profit is:\n      loan_amnt * (1 + 0.25*loan_int_rate)^10 - loan_amnt\n    \"\"\"\n    return loan_amnt * (1 + 0.25 * loan_int_rate) ** 10 - loan_amnt\n\ndef profit_if_default(loan_amnt, loan_int_rate_decimal):\n    \"\"\"\n    If the borrower defaults, we assume default happens 3 years into the loan, \n    and the bank loses 70% of the principal:\n      loan_amnt*(1 + 0.25*loan_int_rate)^3 - 1.7*loan_amnt\n    \"\"\"\n    return loan_amnt * (1 + 0.25 * loan_int_rate) ** 3 - 1.7 * loan_amnt\n\nWe will now compute predicted probabilities (probability of default) for the training data\n\ny_prob_train = model.predict_proba(X_train)[:, 1]  # column 1 = probability of default\n\n\n\n# Split the transformed data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=123\n)\nloan_amnt_array = X_train['loan_amnt'].to_numpy()\nloan_int_rate_array = X_train['loan_int_rate_decimal'].to_numpy()\ny_train_array = y_train.to_numpy()\nprofit_repaid = profit_if_repaid(loan_amnt_array, loan_int_rate_array)\nprofit_default = profit_if_default(loan_amnt_array, loan_int_rate_array)\n\n\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nFile ~/anaconda3/envs/ml-0451/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805, in Index.get_loc(self, key)\n   3804 try:\n-&gt; 3805     return self._engine.get_loc(casted_key)\n   3806 except KeyError as err:\n\nFile index.pyx:167, in pandas._libs.index.IndexEngine.get_loc()\n\nFile index.pyx:196, in pandas._libs.index.IndexEngine.get_loc()\n\nFile pandas/_libs/hashtable_class_helper.pxi:7081, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n\nFile pandas/_libs/hashtable_class_helper.pxi:7089, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n\nKeyError: 'loan_int_rate_decimal'\n\nThe above exception was the direct cause of the following exception:\n\nKeyError                                  Traceback (most recent call last)\n/Users/prashanthbabu/Desktop/machine_learning/csci-0451/posts/new-new-test-post/index.ipynb Cell 22 line 6\n      &lt;a href='vscode-notebook-cell:/Users/prashanthbabu/Desktop/machine_learning/csci-0451/posts/new-new-test-post/index.ipynb#X42sZmlsZQ%3D%3D?line=1'&gt;2&lt;/a&gt; X_train, X_test, y_train, y_test = train_test_split(\n      &lt;a href='vscode-notebook-cell:/Users/prashanthbabu/Desktop/machine_learning/csci-0451/posts/new-new-test-post/index.ipynb#X42sZmlsZQ%3D%3D?line=2'&gt;3&lt;/a&gt;     X, y, test_size=0.2, random_state=123\n      &lt;a href='vscode-notebook-cell:/Users/prashanthbabu/Desktop/machine_learning/csci-0451/posts/new-new-test-post/index.ipynb#X42sZmlsZQ%3D%3D?line=3'&gt;4&lt;/a&gt; )\n      &lt;a href='vscode-notebook-cell:/Users/prashanthbabu/Desktop/machine_learning/csci-0451/posts/new-new-test-post/index.ipynb#X42sZmlsZQ%3D%3D?line=4'&gt;5&lt;/a&gt; loan_amnt_array = X_train['loan_amnt'].to_numpy()\n----&gt; &lt;a href='vscode-notebook-cell:/Users/prashanthbabu/Desktop/machine_learning/csci-0451/posts/new-new-test-post/index.ipynb#X42sZmlsZQ%3D%3D?line=5'&gt;6&lt;/a&gt; loan_int_rate_array = X_train['loan_int_rate_decimal'].to_numpy()\n      &lt;a href='vscode-notebook-cell:/Users/prashanthbabu/Desktop/machine_learning/csci-0451/posts/new-new-test-post/index.ipynb#X42sZmlsZQ%3D%3D?line=6'&gt;7&lt;/a&gt; y_train_array = y_train.to_numpy()\n      &lt;a href='vscode-notebook-cell:/Users/prashanthbabu/Desktop/machine_learning/csci-0451/posts/new-new-test-post/index.ipynb#X42sZmlsZQ%3D%3D?line=7'&gt;8&lt;/a&gt; profit_repaid = profit_if_repaid(loan_amnt_array, loan_int_rate_array)\n\nFile ~/anaconda3/envs/ml-0451/lib/python3.11/site-packages/pandas/core/frame.py:4102, in DataFrame.__getitem__(self, key)\n   4100 if self.columns.nlevels &gt; 1:\n   4101     return self._getitem_multilevel(key)\n-&gt; 4102 indexer = self.columns.get_loc(key)\n   4103 if is_integer(indexer):\n   4104     indexer = [indexer]\n\nFile ~/anaconda3/envs/ml-0451/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812, in Index.get_loc(self, key)\n   3807     if isinstance(casted_key, slice) or (\n   3808         isinstance(casted_key, abc.Iterable)\n   3809         and any(isinstance(x, slice) for x in casted_key)\n   3810     ):\n   3811         raise InvalidIndexError(key)\n-&gt; 3812     raise KeyError(key) from err\n   3813 except TypeError:\n   3814     # If we have a listlike key, _check_indexing_error will raise\n   3815     #  InvalidIndexError. Otherwise we fall through and re-raise\n   3816     #  the TypeError.\n   3817     self._check_indexing_error(key)\n\nKeyError: 'loan_int_rate_decimal'\n\n\n\nNow we are going to find a threshold and identify teh best threshold\n\n# 5. Sweep over thresholds to find the one that maximizes average profit\n\nthresholds = np.linspace(0, 1, 101)\navg_profits = []\n\nfor t in thresholds:\n    # Predict default if probability &gt;= t\n    predicted_default = (y_prob_train &gt;= t).astype(int)\n      # If we predict default, we do NOT give the loan =&gt; profit = 0\n    # If we predict no default, we DO give the loan =&gt; actual profit depends on y_train_array\n    #    - If actual y=0 (no default), profit = profit_repaid\n    #    - If actual y=1 (default), profit = profit_default\n    give_loan = 1 - predicted_default  # 1 = give loan, 0 = no loan\n    # total_profit[i] = give_loan[i] * [ (1 - y[i])*profit_repaid[i] + y[i]*profit_default[i] ]\n    total_profit = give_loan * ((1 - y_train_array) * profit_repaid + y_train_array * profit_default)\n    \n    # Compute average profit per borrower\n    avg_profit = total_profit.mean()\n    avg_profits.append(avg_profit)\n\navg_profits = np.array(avg_profits)\n\n# 6. Identify the best threshold\n\nbest_idx = np.argmax(avg_profits) # index of the best threshold\nbest_threshold = thresholds[best_idx]\n\n\nprint(f\"Best Threshold: {best_threshold:.3f}\")\n\nBest Threshold: 1.000\n\n\n\n# 7. Plot profit vs. threshold\n\nplt.figure(figsize=(8, 5))\nplt.plot(thresholds, avg_profits, label='Profit per Borrower')\nplt.scatter(best_threshold, best_profit, color='red', zorder=10, label='Optimal Threshold')\nplt.title('Profit per Borrower (Training Set) vs. Threshold')\nplt.xlabel('Threshold (Probability of Default)')\nplt.ylabel('Average Profit per Borrower')\nplt.legend()\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/discecting_racial_bias_algo/index.html#plotting-risk-score-percentiles-against-mean-number-of-active-chronic-conditions-within-that-percentile",
    "href": "posts/discecting_racial_bias_algo/index.html#plotting-risk-score-percentiles-against-mean-number-of-active-chronic-conditions-within-that-percentile",
    "title": "Dissecting racial bias in an algorithm used to manage the health of populations",
    "section": "Plotting risk score percentiles against mean number of active chronic conditions within that percentile",
    "text": "Plotting risk score percentiles against mean number of active chronic conditions within that percentile\nOur code below shows us a plot explaining how the algorithm’s risk score percentile (y-axis) increases as the average number of chronic illnesses (x-axis) goes up, with points colored by race. Generally, patients with more chronic illnesses receive a higher risk score.\nHowever, if a Black patient and a White patient both have the same chronic illnesses, the Black patient often ends up with a lower risk score than the White patient. Because the care management program looks for patients with high risk scores, the Black patient with the same health conditions is less likely to be flagged for extra care—this is the key concern the Obermeyer et al. (2019) highlights.\n\nimport numpy as np\nimport seaborn as sns\n\ndf['risk_percentile'] = df['risk_score_t'].rank(pct=True) * 100\ndf['risk_p_bin'] = df['risk_percentile'].round() # Rounding it to the nearest integer\n\n# Group by race & risk percentile; compute mean chronic illnesses\ngrouped = (\n    df.groupby(['race', 'risk_p_bin'], as_index=False)\n      .agg(mean_chronic=('gagne_sum_t', 'mean'))\n)\n\n\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(10, 7))\n\nsns.scatterplot(\n    data=grouped,\n    x='mean_chronic',     \n    y='risk_p_bin',       \n    hue='race',\n    alpha=0.8\n)\n\n\nplt.xlabel(\"Mean Number of Chronic Illnesses\")\nplt.ylabel(\"Risk Score Percentile (binned)\")\nplt.title(\"Risk Score Percentile vs. Mean Chronic Illnesses by Race\")\nplt.legend(title=\"Race\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "posts/discecting_racial_bias_algo/index.html#visualizing-the-relationship-between-risk-score-chronic-illness-and-healthcare-costs",
    "href": "posts/discecting_racial_bias_algo/index.html#visualizing-the-relationship-between-risk-score-chronic-illness-and-healthcare-costs",
    "title": "Dissecting racial bias in an algorithm used to manage the health of populations",
    "section": "Visualizing the Relationship Between Risk Score, Chronic Illness, and Healthcare Costs",
    "text": "Visualizing the Relationship Between Risk Score, Chronic Illness, and Healthcare Costs\nSomething we notice in both our graphs is that White patients (displayed in orange) tend to generate higher medical costs than Black patients (displayed as blue dots) at similar risk score percentiles or similar numbers of chronic illnesses. This finding aligns with the paper’s discussion of a “wedge” between needing care and receiving (or using) care: even when Black and White patients have the same burden of chronic illnesses, White patients often end up with higher total expenditures.\nIt’s also notable that the vast majority of patients have relatively few chronic conditions . Only a small subset of patients have 10 or more illnesses, yet these high-illness groups appear to have an influence on total costs. This illustrates how a minority of patients with many chronic conditions can account for a disproportionately large share of healthcare spending.\n\n# Group for percentile risk score\ngrouped_risk = (\n    df.groupby(['race', 'risk_p_bin'], as_index=False)\n      .agg(mean_cost=('cost_t', 'mean'))\n)\n# Group for numbe rof chronic illness\ngrouped_chronic = (\n    df.groupby(['race', 'gagne_sum_t'], as_index=False)\n      .agg(mean_cost=('cost_t', 'mean'))\n)\n\n# fitting the  subplots, side by side\nfig, axes = plt.subplots(ncols=2, figsize=(12, 5))\n\n# plotting the percentile risk score\nsns.scatterplot(\n    data=grouped_risk,\n    x='risk_p_bin',\n    y='mean_cost',\n    hue='race',\n    alpha=0.8,\n    ax=axes[0]\n)\naxes[0].set_title(\"Mean Expenditure vs. Risk Score Percentile\")\naxes[0].set_xlabel(\"Percentile Risk Score\")\naxes[0].set_ylabel(\"Total Medical Expenditure\")\naxes[0].set_xticks([0, 20, 40, 60, 80, 100])  # Custom x-ticks\n\n# using a log scale for the y-axis\naxes[0].set_yscale('log')\n\n# plotting the number of chronic illnesses\nsns.scatterplot(\n    data=grouped_chronic,\n    x='gagne_sum_t',\n    y='mean_cost',\n    hue='race',\n    alpha=0.8,\n    ax=axes[1]\n)\naxes[1].set_title(\"Mean Expenditure vs. Number of Chronic Illnesses\")\naxes[1].set_xlabel(\"Number of Chronic Illnesses\")\naxes[1].set_ylabel(\"Total Medical Expenditure\")\n\n\n# Custom x-ticks\naxes[1].set_xticks([0, 5, 10, 15])\n\n# using a log scale for the y-axis\naxes[1].set_yscale('log')\n\naxes[1].legend(title=\"Race\", loc=\"upper left\", bbox_to_anchor=(1, 1))\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nIn our code below we calculate percentage of patients with 5 or fewer chronic conditions and see that about 90% of patients have five or fewer chronic conditions, so by focusing on this group, you’re still covering the vast majority of the dataset. That makes it a reasonable choice: it simplifies the analysis while still capturing most patients’ experiences.\n\n# 2. Remove patients with $0 medical costs because log(0) is undefined\ndf = df[df['cost_t'] &gt; 0]\n\n# Determine the percentage of patients with 5 or fewer chronic conditions\ntotal_patients = df.shape[0]\npatients_5_or_fewer = df[df['gagne_sum_t'] &lt;= 5].shape[0]\npercentage_5_or_fewer = (patients_5_or_fewer / total_patients) * 100\nprint(\"Percentage of patients with 5 or fewer chronic conditions: \", (percentage_5_or_fewer))\n\nPercentage of patients with 5 or fewer chronic conditions:  89.79413053000438"
  },
  {
    "objectID": "posts/discecting_racial_bias_algo/index.html#data-preparation-before-modeling",
    "href": "posts/discecting_racial_bias_algo/index.html#data-preparation-before-modeling",
    "title": "Dissecting racial bias in an algorithm used to manage the health of populations",
    "section": "Data preparation before modeling",
    "text": "Data preparation before modeling\n\n# 2. Remove patients with $0 medical costs because log(0) is undefined\ndf = df[df['cost_t'] &gt; 0]\n\n# Determine the percentage of patients with 5 or fewer chronic conditions\ntotal_patients = df.shape[0]\npatients_5_or_fewer = df[df['gagne_sum_t'] &lt;= 5].shape[0]\npercentage_5_or_fewer = (patients_5_or_fewer / total_patients) * 100\nprint(\"Percentage of patients with 5 or fewer chronic conditions: \", (percentage_5_or_fewer))\n\nPercentage of patients with 5 or fewer chronic conditions:  89.79413053000438\n\n\nWe see that about 90% of patients have five or fewer chronic conditions, so by focusing on this group, you’re still covering the vast majority of the dataset. That makes it a reasonable choice: it simplifies the analysis while still capturing most patients’ experiences."
  },
  {
    "objectID": "posts/discecting_racial_bias_algo/index.html#modeling-our-data",
    "href": "posts/discecting_racial_bias_algo/index.html#modeling-our-data",
    "title": "Dissecting racial bias in an algorithm used to manage the health of populations",
    "section": "Modeling our Data",
    "text": "Modeling our Data\nIn our code belwo we perform three main steps to prepare our data for modeling:\n\nLog-Transforming Costs: We create a new column log_cost by taking the natural log of cost_t. This transformation helps manage the large range of healthcare expenses, making it easier for a regression model to handle.\nOne-Hot Encoding Race: We introduce a race_dummy variable where Black patients are assigned a value of 1 and White patients a value of 0. Turning the categorical race variable into a numeric format allows the model to incorporate race as a predictor.\nDefining Predictors and Target: Our predictor variables (X) are the dummy-coded race variable (race_dummy) and the total number of chronic conditions (gagne_sum_t). Our target variable (y) is the log-transformed cost (log_cost).\n\n\n#log-transform of the cost\ndf['log_cost'] = np.log(df['cost_t'])\n\n# one-hot encoding race\ndf['race_dummy'] = (df['race'] == 'black').astype(int)\n\n#Separate the data into predictor variables (X) and the target variable (y)\n#   For predictors, we use the onehot encoded race variavle and the number of chronic conditions.\nX = df[['race_dummy', 'gagne_sum_t']]\ny = df['log_cost']\n\nprint(X['race_dummy'].value_counts())\n\nprint(\"Predictor variables x\")\n\nprint(X.head()) \n\nprint(\"Target variable y\")\n\nprint(y.head())\n\nrace_dummy\n0    5851\n1     998\nName: count, dtype: int64\nPredictor variables x\n    race_dummy  gagne_sum_t\n1            0            3\n8            1            1\n15           0            1\n19           0            0\n21           0            2\nTarget variable y\n1     7.863267\n8     6.907755\n15    7.313220\n19    8.594154\n21    8.318742\nName: log_cost, dtype: float64"
  },
  {
    "objectID": "posts/discecting_racial_bias_algo/index.html#modeling-our-cost-disparity",
    "href": "posts/discecting_racial_bias_algo/index.html#modeling-our-cost-disparity",
    "title": "Dissecting racial bias in an algorithm used to manage the health of populations",
    "section": "Modeling our Cost Disparity",
    "text": "Modeling our Cost Disparity\nIn our code below we built our model to assess the cost disparity. So we do this by building a polynomial regression model to explore the relationship between the number of chronic illnesses, race, and healthcare costs. In order to this we had to do the following steps\n\nTransforming the Data: We applied a log transformation to the cost variable to handle its wide range of values. In addition to that We one-hot encoded race, where Black patients were assigned 1 and White patients were assigned 0.\nGenerating Polynomial Features: Since the relationship between chronic conditions and cost was not linear, we created polynomial features up to degree 11 to capture nonlinearity.\nHyperparameter Tuning: We tested different polynomial degrees (1 to 11) and regularization strengths (Ridge regression with \\(\\alpha = 10^k\\) for \\(k = -4, -3, \\dots, 3, 4\\)). Using cross-validation, we identified the combination that minimized the mean squared error (MSE).\nFitting the Final Model: Once we found the best degree (9) and regularization strength (\\(\\alpha = 10\\)), we trained our final Ridge regression model. We extracted the coefficient for race (\\(w_b\\)), which indicates the impact of being Black on predicted log-cost. We computed \\(e^{w_b}\\), which tells us the relative cost of Black patients compared to White patients with similar illness burdens.\n\n\nimport warnings\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.linear_model import Ridge\n\ndef add_polynomial_features(X, degree):\n    \"\"\"\n    Adds polynomial terms for 'gagne_sum_t' up to the specified degree.\n    \"\"\"\n    X_ = X.copy()\n\n    for j in range(1, degree + 1):\n        X_[f\"poly_{j}\"] = X_[\"gagne_sum_t\"] ** j\n    return X_\n\n# create a hyperparameter grid for the polynomial degree\ndegrees = range(1, 12)               # 1 through 11\nalphas = [10**k for k in range(-4, 5)]  # 10^-4 through 10^4\n\n# Initialize the best score to positive infinity and the best parameters to None\n# cross-validation will update these variables\nbest_score = np.inf\nbest_params = (None, None)  # (degree, alpha)\n\n\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\")\n\n    for deg in degrees:\n        # Create polynomial features up to 'deg'\n        X_poly = add_polynomial_features(X[['gagne_sum_t']], deg)\n        # we include the race dummy column as well\n        X_poly['race_dummy'] = X['race_dummy']\n        \n        for alpha in alphas:\n            # creating a Ridge model with the given alpha\n            model = Ridge(alpha=alpha)\n            \n            # 5-fold cross-validation using negative MSE (sklearn uses negative MSE by default)\n            scores = cross_val_score(model, X_poly, y, cv=5, scoring='neg_mean_squared_error')\n            mean_mse = -np.mean(scores)  # convert negative MSE to MSE\n\n            # Update if we find a better (lower) MSE\n            if mean_mse &lt; best_score:\n                best_score = mean_mse\n                best_params = (deg, alpha)\n\nprint(\"Best degree and alpha:\", best_params)\nprint(\"Cross Validated MSE:\", best_score)\n\n# final model\nbest_degree = best_params[0]\nbest_alpha = best_params[1]\n\n# Build the final model using the polynomial degree and alpha that gave the best MSE\nX_final = add_polynomial_features(X[['gagne_sum_t']], best_degree)\nX_final['race_dummy'] = X['race_dummy']\n\n# Fit the final model\nfinal_model = Ridge(alpha=best_alpha)\nfinal_model.fit(X_final, y)\n\ncoef_names = list(X_final.columns)\ncoefs = final_model.coef_\n\nrace_index = coef_names.index(\"race_dummy\")\nrace_coef = coefs[race_index]\n\n# Compute e^(wb)\nrace_factor = np.exp(race_coef)\n\nprint(\"Race factor (e^(wb)):\", race_factor)\n\nBest degree and alpha: (9, 10)\nCross Validated MSE: 1.206333568523416\nRace factor (e^(wb)): 0.8095004382057049\n\n\n/Users/prashanthbabu/anaconda3/envs/ml-0451/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=2.53171e-22): result may not be accurate.\n  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T"
  },
  {
    "objectID": "posts/discecting_racial_bias_algo/index.html#interpretting-our-results",
    "href": "posts/discecting_racial_bias_algo/index.html#interpretting-our-results",
    "title": "Dissecting racial bias in an algorithm used to manage the health of populations",
    "section": "Interpretting our results:",
    "text": "Interpretting our results:\nThe best polynomial degree was 9, suggesting a complex, nonlinear relationship between chronic conditions and cost. The regularization strength \\(\\alpha = 10\\) helped control overfitting while preserving useful patterns.\nThe race coefficient (\\(w_b\\)) resulted in a computed value of \\(e^{w_b} \\approx 0.81\\), meaning Black patients incur only \\(\\sim 81\\%\\) of the healthcare costs of equally sick White patients. This result aligns with the argument in Obermeyer et al. (2019)—that healthcare cost data underestimates Black patients’ need for care. Since cost data is used to determine who gets extra healthcare resources, this disparity can lead to biased decision-making, where Black patients may be less likely to be enrolled in high-risk management programs despite having the same number of chronic conditions as White patients.\nIn summary, our model supports the claim that cost-based risk scores do not fully capture healthcare need, and the bias disproportionately affects Black patients."
  },
  {
    "objectID": "posts/discecting_racial_bias_algo/index.html#abstract",
    "href": "posts/discecting_racial_bias_algo/index.html#abstract",
    "title": "Dissecting racial bias in an algorithm used to manage the health of populations",
    "section": "",
    "text": "In this project, I aim to replicate and extend the findings of Obermeyer et al. (2019) by exploring how healthcare cost predictions relate to patients’ chronic illness burden and race. Using a randomized dataset, we first visualize the relationship between risk score percentiles, chronic conditions, and medical expenditures, revealing that White patients tend to generate higher costs than Black patients despite similar illness burdens. We then built a Ridge regression model with polynomial features to quantify the disparity in costs between Black and White patients. Our final model estimates that, holding illness burden constant, Black patients incur roughly 81% of the costs incurred by White patients, suggesting that the cost-based risk score underestimates the true care needs of Black patients."
  },
  {
    "objectID": "posts/discecting_racial_bias_algo/index.html#exploring-the-data",
    "href": "posts/discecting_racial_bias_algo/index.html#exploring-the-data",
    "title": "Dissecting racial bias in an algorithm used to manage the health of populations",
    "section": "Exploring the Data",
    "text": "Exploring the Data\nBelow we will accesss the data clean it and explore the different variables and features.\n\nimport pandas as pd\nurl = \"https://gitlab.com/labsysmed/dissecting-bias/-/raw/master/data/data_new.csv?inline=false\"\ndf = pd.read_csv(url)\ndf.head()\n\n\n\n\n\n\n\n\nrisk_score_t\nprogram_enrolled_t\ncost_t\ncost_avoidable_t\nbps_mean_t\nghba1c_mean_t\nhct_mean_t\ncre_mean_t\nldl_mean_t\nrace\n...\ntrig_min-high_tm1\ntrig_min-normal_tm1\ntrig_mean-low_tm1\ntrig_mean-high_tm1\ntrig_mean-normal_tm1\ntrig_max-low_tm1\ntrig_max-high_tm1\ntrig_max-normal_tm1\ngagne_sum_tm1\ngagne_sum_t\n\n\n\n\n0\n1.987430\n0\n1200.0\n0.0\nNaN\n5.4\nNaN\n1.110000\n194.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n7.677934\n0\n2600.0\n0.0\n119.0\n5.5\n40.4\n0.860000\n93.0\nwhite\n...\n0\n1\n0\n0\n1\n0\n0\n1\n4\n3\n\n\n2\n0.407678\n0\n500.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0.798369\n0\n1300.0\n0.0\n117.0\nNaN\nNaN\nNaN\nNaN\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n17.513165\n0\n1100.0\n0.0\n116.0\nNaN\n34.1\n1.303333\n53.0\nwhite\n...\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n\n\n\n\n5 rows × 160 columns\n\n\n\nOur code below checks the ratio of white patients to black patiens before dropping NA values and after dorpping them. There is clearly a big difference in the ratio of black to white people in our dataset, which is something to keep in mind.\n\nrace_counts_bf_clean = df['race'].value_counts()\ndf.dropna(inplace=True)\nrace_counts = df['race'].value_counts()\nprint(\"Count of patients by race before cleaning data\",race_counts_bf_clean)\nprint(\"Count of patients by race after cleaning data\", race_counts)\n\nCount of patients by race before cleaning data race\nwhite    43202\nblack     5582\nName: count, dtype: int64\nCount of patients by race after cleaning data race\nwhite    5911\nblack    1000\nName: count, dtype: int64\n\n\n\nimport  matplotlib.pyplot as plt\nimport seaborn as sns\n# Graph 1: Bar chart of race counts\nplt.figure(figsize=(6, 4))\nplt.bar(race_counts.index, race_counts.values, color=['blue', 'orange'])\nplt.xlabel('Race')\nplt.ylabel('Number of Patients')\nplt.title('Number of Black vs. White Patients')\nplt.show()\n\n\n\n\n\n\n\n\nBelow is a scatter plot to visualize the Risk Score vs the Cost by race and see a lot of clustering. So we will need to further clean our data to get better visualizations.\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=df, x=\"risk_score_t\", y=\"cost_t\", hue=\"race\", alpha=0.7)\n\n# Labels and title\nplt.xlabel(\"Risk Score\")\nplt.ylabel(\"Cost\")\nplt.title(\"Risk Score vs Cost by Race\")\nplt.show()"
  },
  {
    "objectID": "posts/discecting_racial_bias_algo/index.html#discussion",
    "href": "posts/discecting_racial_bias_algo/index.html#discussion",
    "title": "Dissecting racial bias in an algorithm used to manage the health of populations",
    "section": "Discussion",
    "text": "Discussion\nOur modeling process used polynomial feature expansion and regularized linear regression which allowed us to capture the nonlinear relationship between chronic conditions and cost. The final model’s race coefficient, suggests that Black patients’ predicted expenditures are about 81% of those of White patients with the same number of chronic conditions. This finding supports the “wedge” hypothesis discussed by Obermeyer et al. (2019): even when Black and White patients are equally sick, Black patients tend to have lower healthcare costs, likely due to systemic inequities in access and utilization of care. In relation to the formal statistical discrimination criteria from Barocas, Hardt, and Narayanan (2023), the bias in this algorithm is best described by a failure of the separation criterion. In an ideal scenario, the classifier (or risk score) should yield equal error rates—that is, for any given risk score, the probability of high health need should be equal across racial groups. Our analysis shows that this is not the case: Black patients, at a given risk score, exhibit a higher burden of chronic illness, indicating that the algorithm’s misclassification rates differ by race. This violation of separation shows how using cost as a proxy for health can introduce systematic bias, ultimately disadvantaging Black patients. Overall, through this project I learned how to build a Ridge regression model using polynomial features, as well as how to tune hyperparameters effectively. This process revealed how these modeling techniques can uncover hidden biases in decision-making algorithms, underscoring the need for more equitable measures when predicting healthcare needs."
  }
]
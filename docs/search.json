[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this bloghshjs"
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Timnit Gebru",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-new-test-post/index.html#math",
    "href": "posts/new-new-test-post/index.html#math",
    "title": "Timnit Gebru",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "Predicting a penguin’s species based on its physical measurements is an interesting challenge in data analysis and machine learning. In this blog, we’ll explore the Palmer Penguins dataset, which was collected by Dr. Kristen Gorman and the Palmer Station, to analyze biological measurements of three penguin species in Antarctica. Through data visualization and feature selection, we’ll uncover key insights and build a classification model that achieves perfect accuracy using a carefully chosen set of features. Along the way, we’ll discuss our findings and ensure a reproducible and insightful approach to species classification. ### Loading Data We will now use the Pandas function to read the CSV and also take a look at the data and the different variables and columns we have in our dataset before we do and data explorations and analysis.\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN"
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "Classifying Palmer Penguins\n\n\n\n\n\nA blog post about classifying penguins with machine learning using logistic Regression.\n\n\n\n\n\nFeb 20, 2025\n\n\nPB\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Post\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nTimnit Gebru\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/example-blog-post/index.html#data-cleaning",
    "href": "posts/example-blog-post/index.html#data-cleaning",
    "title": "Classifying Palmer Penguins",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nOur dataset contains numerous variables, including comments and region information, that are not relevant for training our model. Since we will be focusing on variables such as island, culmen length, culmen depth, flipper length, and body mass, we will remove unnecessary columns before proceeding with data exploration, visualization, and model training. Let’s start by loading the necessary packages for data cleaning, visualization, and model training. We will also convert categorical feature columns like Sex and Island into one-hot encoded 0-1( or true or false) columns using the pd.get_dummies function. Additionally, we can see that Species is a categorical variable, but instead of one-hot encoding, we will use label encoding to convert it into numerical labels: 0 for Adelie, 1 for Chinstrap, and 2 for Gentoo. This transformation will make data visualization and model training much easier.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC # support vector classifier\nfrom mlxtend.plotting import plot_decision_regions # for visualization later\nfrom sklearn.preprocessing import LabelEncoder\n\n# Encode categorical features and label\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n    df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\", \"Stage\"], axis=1)\n    df = df[df[\"Sex\"] != \".\"]\n    df = df.dropna()\n    y = le.transform(df[\"Species\"])\n    df = df.drop([\"Species\"], axis=1)\n    # One-hot encode categorical variables\n    df =(pd.get_dummies(df)).astype(int)\n\n    return df, y\n\n# Prepare training data\nX_train, y_train = prepare_data(train)\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40\n16\n187\n3200\n9\n-24\n0\n1\n0\n0\n1\n1\n0\n\n\n1\n49\n19\n210\n3950\n9\n-24\n0\n1\n0\n0\n1\n0\n1\n\n\n2\n50\n15\n218\n5700\n8\n-25\n1\n0\n0\n0\n1\n0\n1\n\n\n3\n45\n14\n210\n4200\n7\n-25\n1\n0\n0\n0\n1\n1\n0\n\n\n4\n51\n18\n203\n4100\n9\n-24\n0\n1\n0\n0\n1\n0\n1\n\n\n\n\n\n\n\n\nVisualizing the data\nThe bar chart below shows the number of penguins of each species on different islands, helping us identify patterns in species distribution. Interestingly, we observe: - Torgersen Island: Only Adelie penguins are present, with a population of about 30-40 individuals. - Dream Island: Has both Adelie and Chinstrap penguins, with Chinstrap being the dominant species. - Biscoe Island: Has both Adelie and Gentoo penguins, with Gentoo having the largest population overall.\nChinstrap penguins are only found on Dream Island, while Gentoo penguins are exclusive to Biscoe Island. Adelie penguins, on the other hand, are the most widespread, appearing on all three islands. Based on this distribution, the island where a penguin is found could be a useful feature for predicting its species.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n# Map species labels back to names\nspecies_map = {0: 'Adelie', 1: 'Chinstrap', 2: 'Gentoo'}\nspecies_island_counts = X_train.copy()\nspecies_island_counts[\"Species\"] = [species_map[label] for label in y_train]\n\n# Convert one-hot encoded islands back to a single column\nspecies_island_counts[\"Island\"] = species_island_counts[[\"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]].idxmax(axis=1)\nspecies_island_counts[\"Island\"] = species_island_counts[\"Island\"].str.replace(\"Island_\", \"\")\n\n# Count number of penguins per species per island\nplot_data = species_island_counts.groupby([\"Island\", \"Species\"]).size().reset_index(name=\"Count\")\n\n# Plot\nplt.figure(figsize=(8, 5))\nsns.barplot(data=plot_data, x=\"Island\", y=\"Count\", hue=\"Species\", palette=\"mako\")\nplt.xlabel(\"Island\")\nplt.ylabel(\"Number of Penguins\")\nplt.title(\"Penguin Species Distribution Across Islands\")\nplt.legend(title=\"Species\")\nplt.show()\n\n\n\n\n\n\n\n\nBased on the graph above, we can see that by simply looking at the islands, we can somewhat predict the species of the penguin. This is a good example of a feature that could help predict the species. However, the model would be much more efficient if each island only hosted one species of penguin. Since some islands have more than one species, we might want to explore additional features. For example, if a penguin is on Biscoe Island and has a certain Culmen length and Culmen depth, can we make more accurate predictions based on those measurements? To explore this, we will create a graph to assess whether including Culmen lenght and Culmen depth is a useful feature for predicting the species on each island.\n\n\n# Plotting the relationship between Culmen Length and Culmen Depth for each species on each island\nsns.relplot(data =train, hue=\"Species\", y = 'Culmen Depth (mm)', x =  'Culmen Length (mm)',col = 'Island')\n\n&lt;seaborn.axisgrid.FacetGrid at 0x149d2fc10&gt;\n\n\n\n\n\n\n\n\n\nThe graph above looks at the relationship between Culmen Depth (mm) and Culmen Length (mm) for different penguin species, separated by island. Each species is color-coded to highlight patterns in their beak dimensions. From this graph, we can observe: - Gentoo penguins (orange) tend to have longer culmen lengths and shallower culmen depths. - Adelie penguins (green) have moderate culmen lengths and a wide range of culmen depths. - Chinstrap penguins (blue) have longer culmen lenghts compared to Adelie penguins but exhibit similar culmen Depths. ## Can Culmen Features Help in Classification? Looking at the separability of species by island: - Biscoe Island: Gentoo and Adelie penguins are linearly separable, meaning a simple model could classify them effectively based on culmen features. - Dream Island: Chinstrap and Adelie penguins overlap in culmen depth, making them harder to separate linearly. However, their culmen lengths show some distinction, which could aid classification. - Torgersen Island: Since only Adelie penguins are found here, culmen features are irrelevant for classification on this island.\nThis suggests that culmen depth and length can be strong features for classifying species, especially when combined with island location. ## Exploring Culmen Features in relation to Flipper Lenght\n\nsns.relplot(data = train, y = 'Culmen Length (mm)', x =  'Flipper Length (mm)',  hue = 'Species').set(title='Relation between Flipper Length and Culmen Length')\nsns.relplot(data = train, y = 'Culmen Depth (mm)', x =  'Flipper Length (mm)',  hue = 'Species').set(title='Relation between Flipper Length and Culmen Depth')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe first graph explores the relationship between flipper length and culmen length across penguin species. Gentoo penguins have both longer flipper lengths and culmen lengths compared to the other species, making them easily distinguishable. Adelie penguins, in contrast, have shorter values for both features, clustering in the lower-left section of the graph. Chinstrap penguins overlap with Adelie penguins in flipper length but tend to have slightly longer culmen lengths, creating some classification challenges.\nThe second graph examines the relationship between flipper length and culmen depth. Here, Gentoo penguins are clearly separable from the other two species due to their significantly shallower culmen depths, forming a distinct cluster in the lower section. Howeber the Adelie and Chinstrap penguins overlap a lot more, particularly in flipper length and culmen depth. While Gentoo penguins can be classified easily, distinguishing between Adelie and Chinstrap penguins would be really difficult because of this clustering.\n\ntrain.groupby('Species').agg({\n    'Flipper Length (mm)': 'mean',\n    'Culmen Length (mm)': 'mean',\n    'Culmen Depth (mm)': 'mean'\n}).reset_index()\n\n\n\n\n\n\n\n\nSpecies\nFlipper Length (mm)\nCulmen Length (mm)\nCulmen Depth (mm)\n\n\n\n\n0\nAdelie Penguin (Pygoscelis adeliae)\n190.084034\n38.970588\n18.409244\n\n\n1\nChinstrap penguin (Pygoscelis antarctica)\n196.000000\n48.826316\n18.366667\n\n\n2\nGentoo penguin (Pygoscelis papua)\n216.752577\n47.073196\n14.914433\n\n\n\n\n\n\n\nThis code above calculates the mean values of flipper length, culmen length, and culmen depth for each penguin species using the .groupby() function. The table summarizes the average flipper length, culmen length, and culmen depth for each penguin species. Gentoo penguins have the longest flipper and culmen lengths but the shallowest culmen depth. Chinstrap penguins have longer culmen lengths than Adelie penguins but similar culmen depths. Adelie penguins have the shortest flipper and culmen lengths but slightly deeper culmens than Chinstrap. These differences highlight key features that can help classify penguin species."
  },
  {
    "objectID": "posts/example-blog-post/index.html#now-we-are-going-to-chose-feature-to-train-our-model",
    "href": "posts/example-blog-post/index.html#now-we-are-going-to-chose-feature-to-train-our-model",
    "title": "Classifying Palmer Penguins",
    "section": "Now we are going to chose feature to train our model",
    "text": "Now we are going to chose feature to train our model\nBy using the combinations function from the itertools package, we generate different combinations of categorical and continuous features. So we will pair categorical variables like Sex and Clutch Completion with continuous variables such as Culmen Length, Culmen Depth, and Flipper Length. This allows us to explore various feature combinations and evaluate which ones might be most useful for accurately classifying the penguin species.\n\nfrom itertools import combinations\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\n\nbest_score = 0\nbest_features = None\n\nfor qual in all_qual_cols:\n    qual_cols = [col for col in X_train.columns if qual in col]  # Ensure categorical features are one-hot encoded\n    for pair in combinations(all_quant_cols, 2):\n        cols = qual_cols + list(pair)\n        \n        # Train a logistic regression model to evaluate feature combinations\n        model = LogisticRegression(max_iter=1000)  # Increased iterations for better convergence\n        scores = cross_val_score(model, X_train[cols], y_train, cv=5, scoring='accuracy')\n        \n        avg_score = np.mean(scores)\n        if avg_score &gt; best_score:\n            best_score = avg_score\n            best_features = cols\n\nprint(\"Best features:\", best_features)\n\nBest features: ['Sex_FEMALE', 'Sex_MALE', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n\n\nAccording to itertools, the best features to use are ‘Sex_FEMALE’, ‘Sex_MALE’, ‘Culmen Length (mm)’, and ‘Culmen Depth (mm)’. However, we wanted to explore how our model would perform based on our exploration of the island features along with the Culmen features. Thus, we will now reassign these as the best features and use them to train our model.\n\n#Rearranging Best featrues so that the first two columns are the quantitative columns and the rest are the qualitative columns\nbest_features = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\nbest_features\n\n['Culmen Length (mm)',\n 'Culmen Depth (mm)',\n 'Island_Biscoe',\n 'Island_Dream',\n 'Island_Torgersen']"
  },
  {
    "objectID": "posts/example-blog-post/index.html#let-us-now-prepare-our-test-dataset",
    "href": "posts/example-blog-post/index.html#let-us-now-prepare-our-test-dataset",
    "title": "Classifying Palmer Penguins",
    "section": "Let us now prepare our Test Dataset",
    "text": "Let us now prepare our Test Dataset\n\n# Load test data\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\n# Prepare test data\nX_test, y_test = prepare_data(test)"
  },
  {
    "objectID": "posts/example-blog-post/index.html#training-and-evaluating-our-model",
    "href": "posts/example-blog-post/index.html#training-and-evaluating-our-model",
    "title": "Classifying Palmer Penguins",
    "section": "Training and evaluating our Model",
    "text": "Training and evaluating our Model\nIn the code below, we use a Logistic Regression model and train it on the selected features: [‘Culmen Length (mm)’, ‘Culmen Depth (mm)’, ‘Island_Biscoe’, ‘Island_Dream’, ‘Island_Torgersen’]. We then evaluate the accuracy using the LR.score function. Our training accuracy was 99%, and our testing accuracy—measuring how well the model performed on unseen data—was 100%. The confusion matrix confirms that we correctly classified all penguins with no misclassifications. Specifically, our model correctly identified 31 Adelie, 11 Chinstrap, and 26 Gentoo penguins, achieving perfect classification.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nLR = LogisticRegression()\nLR.fit(X_train[best_features], y_train)\n\n\n\n# Predict on test set\ny_pred = LR.predict(X_test[best_features])\n\n# Evaluate the model\nscore_train = LR.score(X_train[best_features], y_train)\nscore_test = LR.score(X_test[best_features], y_test)\n\nprint(\"Training Accuracy:\", score_train)\nprint(\"Test Accuracy:\", score_test)\n\nprint(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n\nTraining Accuracy: 0.9921875\nTest Accuracy: 1.0\n\nConfusion Matrix:\n [[31  0  0]\n [ 0 11  0]\n [ 0  0 26]]"
  },
  {
    "objectID": "posts/example-blog-post/index.html#plotting-our-results",
    "href": "posts/example-blog-post/index.html#plotting-our-results",
    "title": "Classifying Palmer Penguins",
    "section": "Plotting our results",
    "text": "Plotting our results\nThis code below helps us visualize the decision regions of our classification model by plotting how different penguin species are separated based on culmen features and island locations. It creates a grid of values for the culmen length and depth, predicts species across the grid. Each subplot represents a different island, showing how the model’s decision boundaries change depending on the island feature. This helps us understand how the model differentiates between Adelie, Chinstrap, and Gentoo penguins on each island.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y, title):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize=(7 * len(qual_features), 3))  # doing this to fit three plots side by side\n    fig.suptitle(title, fontsize=14)\n\n    # Create a grid\n    grid_x = np.linspace(x0.min(), x0.max(), 501)\n    grid_y = np.linspace(x1.min(), x1.max(), 501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    if len(qual_features) == 1:\n        axarr = [axarr] \n\n    for i, ax in enumerate(axarr):\n        XY = pd.DataFrame({\n            X.columns[0]: XX,\n            X.columns[1]: YY\n        })\n\n        for j in qual_features:\n            XY[j] = 0\n\n        XY[qual_features[i]] = 1\n\n        p = model.predict(XY)\n        p = p.reshape(xx.shape)\n        \n        # Use contour plot to visualize the predictions\n        ax.contourf(xx, yy, p, cmap=\"jet\", alpha=0.2, vmin=0, vmax=2)\n\n        ix = X[qual_features[i]] == 1\n        ax.scatter(x0[ix], x1[ix], c=y[ix], cmap=\"jet\", vmin=0, vmax=2)\n        \n        ax.set(xlabel=X.columns[0], ylabel=X.columns[1], title=qual_features[i])\n\n    patches = [Patch(color=color, label=spec) for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"])]\n    fig.legend(handles=patches, title=\"Species\", loc=\"upper right\")\n\n    plt.tight_layout(rect=[0, 0, 0.9, 1])\n    plt.show()\n\n# Run function for training and test sets\nplot_regions(LR, X_train[best_features], y_train, title=\"Training Set\")\nplot_regions(LR, X_test[best_features], y_pred, title=\"Test Set\")"
  },
  {
    "objectID": "posts/example-blog-post/blog1.html",
    "href": "posts/example-blog-post/blog1.html",
    "title": "Goal of Project",
    "section": "",
    "text": "---\ntitle: Hello Blog\nauthor: PB\ndate: '2025-02-20'\nimage: \"image.jpg\"\ndescription: \"A Blog post about classifying penguins with machine learning.\"\nformat: html\n---\nPredicting a penguin’s species based on its physical measurements is an interesting challenge in data analysis and machine learning. In this blog, we’ll explore the Palmer Penguins dataset, which was collected by Dr. Kristen Gorman and the Palmer Station, to analyze biological measurements of three penguin species in Antarctica. Through data visualization and feature selection, we’ll uncover key insights and build a classification model that achieves perfect accuracy using a carefully chosen set of features. Along the way, we’ll discuss our findings and ensure a reproducible and insightful approach to species classification. ### Loading Data We will now use the Pandas function to read the CSV and also take a look at the data and the different variables and columns we have in our dataset before we do and data explorations and analysis.\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN"
  },
  {
    "objectID": "posts/example-blog-post/blog1.html#data-cleaning",
    "href": "posts/example-blog-post/blog1.html#data-cleaning",
    "title": "Goal of Project",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nOur dataset contains numerous variables, including comments and region information, that are not relevant for training our model. Since we will be focusing on variables such as island, culmen length, culmen depth, flipper length, and body mass, we will remove unnecessary columns before proceeding with data exploration, visualization, and model training. Let’s start by loading the necessary packages for data cleaning, visualization, and model training. We will also convert categorical feature columns like Sex and Island into one-hot encoded 0-1( or true or false) columns using the pd.get_dummies function. Additionally, we can see that Species is a categorical variable, but instead of one-hot encoding, we will use label encoding to convert it into numerical labels: 0 for Adelie, 1 for Chinstrap, and 2 for Gentoo. This transformation will make data visualization and model training much easier.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC # support vector classifier\nfrom mlxtend.plotting import plot_decision_regions # for visualization later\nfrom sklearn.preprocessing import LabelEncoder\n\n# Encode categorical features and label\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n    df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\", \"Stage\"], axis=1)\n    df = df[df[\"Sex\"] != \".\"]\n    df = df.dropna()\n    y = le.transform(df[\"Species\"])\n    df = df.drop([\"Species\"], axis=1)\n    # One-hot encode categorical variables\n    df =(pd.get_dummies(df)).astype(int)\n\n    return df, y\n\n# Prepare training data\nX_train, y_train = prepare_data(train)\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40\n16\n187\n3200\n9\n-24\n0\n1\n0\n0\n1\n1\n0\n\n\n1\n49\n19\n210\n3950\n9\n-24\n0\n1\n0\n0\n1\n0\n1\n\n\n2\n50\n15\n218\n5700\n8\n-25\n1\n0\n0\n0\n1\n0\n1\n\n\n3\n45\n14\n210\n4200\n7\n-25\n1\n0\n0\n0\n1\n1\n0\n\n\n4\n51\n18\n203\n4100\n9\n-24\n0\n1\n0\n0\n1\n0\n1\n\n\n\n\n\n\n\n\nVisualizing the data\nThe bar chart below shows the number of penguins of each species on different islands, helping us identify patterns in species distribution. Interestingly, we observe: - Torgersen Island: Only Adelie penguins are present, with a population of about 30-40 individuals. - Dream Island: Has both Adelie and Chinstrap penguins, with Chinstrap being the dominant species. - Biscoe Island: Has both Adelie and Gentoo penguins, with Gentoo having the largest population overall.\nChinstrap penguins are only found on Dream Island, while Gentoo penguins are exclusive to Biscoe Island. Adelie penguins, on the other hand, are the most widespread, appearing on all three islands. Based on this distribution, the island where a penguin is found could be a useful feature for predicting its species.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n# Map species labels back to names\nspecies_map = {0: 'Adelie', 1: 'Chinstrap', 2: 'Gentoo'}\nspecies_island_counts = X_train.copy()\nspecies_island_counts[\"Species\"] = [species_map[label] for label in y_train]\n\n# Convert one-hot encoded islands back to a single column\nspecies_island_counts[\"Island\"] = species_island_counts[[\"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]].idxmax(axis=1)\nspecies_island_counts[\"Island\"] = species_island_counts[\"Island\"].str.replace(\"Island_\", \"\")\n\n# Count number of penguins per species per island\nplot_data = species_island_counts.groupby([\"Island\", \"Species\"]).size().reset_index(name=\"Count\")\n\n# Plot\nplt.figure(figsize=(8, 5))\nsns.barplot(data=plot_data, x=\"Island\", y=\"Count\", hue=\"Species\", palette=\"mako\")\nplt.xlabel(\"Island\")\nplt.ylabel(\"Number of Penguins\")\nplt.title(\"Penguin Species Distribution Across Islands\")\nplt.legend(title=\"Species\")\nplt.show()\n\n\n\n\n\n\n\n\nBased on the graph above, we can see that by simply looking at the islands, we can somewhat predict the species of the penguin. This is a good example of a feature that could help predict the species. However, the model would be much more efficient if each island only hosted one species of penguin. Since some islands have more than one species, we might want to explore additional features. For example, if a penguin is on Biscoe Island and has a certain Culmen length and Culmen depth, can we make more accurate predictions based on those measurements? To explore this, we will create a graph to assess whether including Culmen lenght and Culmen depth is a useful feature for predicting the species on each island.\n\n\n# Plotting the relationship between Culmen Length and Culmen Depth for each species on each island\nsns.relplot(data =train, hue=\"Species\", y = 'Culmen Depth (mm)', x =  'Culmen Length (mm)',col = 'Island')\n\n\n\n\n\n\n\n\nThe graph above looks at the relationship between Culmen Depth (mm) and Culmen Length (mm) for different penguin species, separated by island. Each species is color-coded to highlight patterns in their beak dimensions. From this graph, we can observe: - Gentoo penguins (orange) tend to have longer culmen lengths and shallower culmen depths. - Adelie penguins (green) have moderate culmen lengths and a wide range of culmen depths. - Chinstrap penguins (blue) have longer culmen lenghts compared to Adelie penguins but exhibit similar culmen Depths. ## Can Culmen Features Help in Classification? Looking at the separability of species by island: - Biscoe Island: Gentoo and Adelie penguins are linearly separable, meaning a simple model could classify them effectively based on culmen features. - Dream Island: Chinstrap and Adelie penguins overlap in culmen depth, making them harder to separate linearly. However, their culmen lengths show some distinction, which could aid classification. - Torgersen Island: Since only Adelie penguins are found here, culmen features are irrelevant for classification on this island.\nThis suggests that culmen depth and length can be strong features for classifying species, especially when combined with island location. ## Exploring Culmen Features in relation to Flipper Lenght\n\nsns.relplot(data = train, y = 'Culmen Length (mm)', x =  'Flipper Length (mm)',  hue = 'Species').set(title='Relation between Flipper Length and Culmen Length')\nsns.relplot(data = train, y = 'Culmen Depth (mm)', x =  'Flipper Length (mm)',  hue = 'Species').set(title='Relation between Flipper Length and Culmen Depth')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe first graph explores the relationship between flipper length and culmen length across penguin species. Gentoo penguins have both longer flipper lengths and culmen lengths compared to the other species, making them easily distinguishable. Adelie penguins, in contrast, have shorter values for both features, clustering in the lower-left section of the graph. Chinstrap penguins overlap with Adelie penguins in flipper length but tend to have slightly longer culmen lengths, creating some classification challenges.\nThe second graph examines the relationship between flipper length and culmen depth. Here, Gentoo penguins are clearly separable from the other two species due to their significantly shallower culmen depths, forming a distinct cluster in the lower section. Howeber the Adelie and Chinstrap penguins overlap a lot more, particularly in flipper length and culmen depth. While Gentoo penguins can be classified easily, distinguishing between Adelie and Chinstrap penguins would be really difficult because of this clustering.\n\ntrain.groupby('Species').agg({\n    'Flipper Length (mm)': 'mean',\n    'Culmen Length (mm)': 'mean',\n    'Culmen Depth (mm)': 'mean'\n}).reset_index()\n\n\n\n\n\n\n\n\nSpecies\nFlipper Length (mm)\nCulmen Length (mm)\nCulmen Depth (mm)\n\n\n\n\n0\nAdelie Penguin (Pygoscelis adeliae)\n190.084034\n38.970588\n18.409244\n\n\n1\nChinstrap penguin (Pygoscelis antarctica)\n196.000000\n48.826316\n18.366667\n\n\n2\nGentoo penguin (Pygoscelis papua)\n216.752577\n47.073196\n14.914433\n\n\n\n\n\n\n\nThis code above calculates the mean values of flipper length, culmen length, and culmen depth for each penguin species using the .groupby() function. The table summarizes the average flipper length, culmen length, and culmen depth for each penguin species. Gentoo penguins have the longest flipper and culmen lengths but the shallowest culmen depth. Chinstrap penguins have longer culmen lengths than Adelie penguins but similar culmen depths. Adelie penguins have the shortest flipper and culmen lengths but slightly deeper culmens than Chinstrap. These differences highlight key features that can help classify penguin species."
  },
  {
    "objectID": "posts/example-blog-post/blog1.html#now-we-are-going-to-chose-feature-to-train-our-model",
    "href": "posts/example-blog-post/blog1.html#now-we-are-going-to-chose-feature-to-train-our-model",
    "title": "Goal of Project",
    "section": "Now we are going to chose feature to train our model",
    "text": "Now we are going to chose feature to train our model\nBy using the combinations function from the itertools package, we generate different combinations of categorical and continuous features. So we will pair categorical variables like Sex and Clutch Completion with continuous variables such as Culmen Length, Culmen Depth, and Flipper Length. This allows us to explore various feature combinations and evaluate which ones might be most useful for accurately classifying the penguin species.\n\nfrom itertools import combinations\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\n\nbest_score = 0\nbest_features = None\n\nfor qual in all_qual_cols:\n    qual_cols = [col for col in X_train.columns if qual in col]  # Ensure categorical features are one-hot encoded\n    for pair in combinations(all_quant_cols, 2):\n        cols = qual_cols + list(pair)\n        \n        # Train a logistic regression model to evaluate feature combinations\n        model = LogisticRegression(max_iter=1000)  # Increased iterations for better convergence\n        scores = cross_val_score(model, X_train[cols], y_train, cv=5, scoring='accuracy')\n        \n        avg_score = np.mean(scores)\n        if avg_score &gt; best_score:\n            best_score = avg_score\n            best_features = cols\n\nprint(\"Best features:\", best_features)\n\nBest features: ['Sex_FEMALE', 'Sex_MALE', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n\n\nAccording to itertools, the best features to use are ‘Sex_FEMALE’, ‘Sex_MALE’, ‘Culmen Length (mm)’, and ‘Culmen Depth (mm)’. However, we wanted to explore how our model would perform based on our exploration of the island features along with the Culmen features. Thus, we will now reassign these as the best features and use them to train our model.\n\n#Rearranging Best featrues so that the first two columns are the quantitative columns and the rest are the qualitative columns\nbest_features = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\nbest_features\n\n['Culmen Length (mm)',\n 'Culmen Depth (mm)',\n 'Island_Biscoe',\n 'Island_Dream',\n 'Island_Torgersen']"
  },
  {
    "objectID": "posts/example-blog-post/blog1.html#let-us-now-prepare-our-test-dataset",
    "href": "posts/example-blog-post/blog1.html#let-us-now-prepare-our-test-dataset",
    "title": "Goal of Project",
    "section": "Let us now prepare our Test Dataset",
    "text": "Let us now prepare our Test Dataset\n\n# Load test data\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\n# Prepare test data\nX_test, y_test = prepare_data(test)"
  },
  {
    "objectID": "posts/example-blog-post/blog1.html#training-and-evaluating-our-model",
    "href": "posts/example-blog-post/blog1.html#training-and-evaluating-our-model",
    "title": "Goal of Project",
    "section": "Training and evaluating our Model",
    "text": "Training and evaluating our Model\nIn the code below, we use a Logistic Regression model and train it on the selected features: [‘Culmen Length (mm)’, ‘Culmen Depth (mm)’, ‘Island_Biscoe’, ‘Island_Dream’, ‘Island_Torgersen’]. We then evaluate the accuracy using the LR.score function. Our training accuracy was 99%, and our testing accuracy—measuring how well the model performed on unseen data—was 100%. The confusion matrix confirms that we correctly classified all penguins with no misclassifications. Specifically, our model correctly identified 31 Adelie, 11 Chinstrap, and 26 Gentoo penguins, achieving perfect classification.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nLR = LogisticRegression()\nLR.fit(X_train[best_features], y_train)\n\n\n\n# Predict on test set\ny_pred = LR.predict(X_test[best_features])\n\n# Evaluate the model\nscore_train = LR.score(X_train[best_features], y_train)\nscore_test = LR.score(X_test[best_features], y_test)\n\nprint(\"Training Accuracy:\", score_train)\nprint(\"Test Accuracy:\", score_test)\n\nprint(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n\nTraining Accuracy: 0.9921875\nTest Accuracy: 1.0\n\nConfusion Matrix:\n [[31  0  0]\n [ 0 11  0]\n [ 0  0 26]]"
  },
  {
    "objectID": "posts/example-blog-post/blog1.html#plotting-our-results",
    "href": "posts/example-blog-post/blog1.html#plotting-our-results",
    "title": "Goal of Project",
    "section": "Plotting our results",
    "text": "Plotting our results\nThis code below helps us visualize the decision regions of our classification model by plotting how different penguin species are separated based on culmen features and island locations. It creates a grid of values for the culmen length and depth, predicts species across the grid. Each subplot represents a different island, showing how the model’s decision boundaries change depending on the island feature. This helps us understand how the model differentiates between Adelie, Chinstrap, and Gentoo penguins on each island.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y, title):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize=(7 * len(qual_features), 3))  # doing this to fit three plots side by side\n    fig.suptitle(title, fontsize=14)\n\n    # Create a grid\n    grid_x = np.linspace(x0.min(), x0.max(), 501)\n    grid_y = np.linspace(x1.min(), x1.max(), 501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    if len(qual_features) == 1:\n        axarr = [axarr] \n\n    for i, ax in enumerate(axarr):\n        XY = pd.DataFrame({\n            X.columns[0]: XX,\n            X.columns[1]: YY\n        })\n\n        for j in qual_features:\n            XY[j] = 0\n\n        XY[qual_features[i]] = 1\n\n        p = model.predict(XY)\n        p = p.reshape(xx.shape)\n        \n        # Use contour plot to visualize the predictions\n        ax.contourf(xx, yy, p, cmap=\"jet\", alpha=0.2, vmin=0, vmax=2)\n\n        ix = X[qual_features[i]] == 1\n        ax.scatter(x0[ix], x1[ix], c=y[ix], cmap=\"jet\", vmin=0, vmax=2)\n        \n        ax.set(xlabel=X.columns[0], ylabel=X.columns[1], title=qual_features[i])\n\n    patches = [Patch(color=color, label=spec) for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"])]\n    fig.legend(handles=patches, title=\"Species\", loc=\"upper right\")\n\n    plt.tight_layout(rect=[0, 0, 0.9, 1])\n    plt.show()\n\n# Run function for training and test sets\nplot_regions(LR, X_train[best_features], y_train, title=\"Training Set\")\nplot_regions(LR, X_test[best_features], y_pred, title=\"Test Set\")"
  },
  {
    "objectID": "posts/Penguins/index.html",
    "href": "posts/Penguins/index.html",
    "title": "Classifying Palmer Penguins",
    "section": "",
    "text": "Predicting a penguin’s species based on its physical measurements is an interesting challenge in data analysis and machine learning. In this blog, we’ll explore the Palmer Penguins dataset, which was collected by Dr. Kristen Gorman and the Palmer Station, to analyze biological measurements of three penguin species in Antarctica. Through data visualization and feature selection, we’ll uncover key insights and build a classification model that achieves perfect accuracy using a carefully chosen set of features. Along the way, we’ll discuss our findings and ensure a reproducible and insightful approach to species classification. ### Loading Data We will now use the Pandas function to read the CSV and also take a look at the data and the different variables and columns we have in our dataset before we do and data explorations and analysis.\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN"
  },
  {
    "objectID": "posts/Penguins/index.html#data-cleaning",
    "href": "posts/Penguins/index.html#data-cleaning",
    "title": "Classifying Palmer Penguins",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nOur dataset contains numerous variables, including comments and region information, that are not relevant for training our model. Since we will be focusing on variables such as island, culmen length, culmen depth, flipper length, and body mass, we will remove unnecessary columns before proceeding with data exploration, visualization, and model training. Let’s start by loading the necessary packages for data cleaning, visualization, and model training. We will also convert categorical feature columns like Sex and Island into one-hot encoded 0-1( or true or false) columns using the pd.get_dummies function. Additionally, we can see that Species is a categorical variable, but instead of one-hot encoding, we will use label encoding to convert it into numerical labels: 0 for Adelie, 1 for Chinstrap, and 2 for Gentoo. This transformation will make data visualization and model training much easier.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC # support vector classifier\nfrom mlxtend.plotting import plot_decision_regions # for visualization later\nfrom sklearn.preprocessing import LabelEncoder\n\n# Encode categorical features and label\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n    df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\", \"Stage\"], axis=1)\n    df = df[df[\"Sex\"] != \".\"]\n    df = df.dropna()\n    y = le.transform(df[\"Species\"])\n    df = df.drop([\"Species\"], axis=1)\n    # One-hot encode categorical variables\n    df =(pd.get_dummies(df)).astype(int)\n\n    return df, y\n\n# Prepare training data\nX_train, y_train = prepare_data(train)\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40\n16\n187\n3200\n9\n-24\n0\n1\n0\n0\n1\n1\n0\n\n\n1\n49\n19\n210\n3950\n9\n-24\n0\n1\n0\n0\n1\n0\n1\n\n\n2\n50\n15\n218\n5700\n8\n-25\n1\n0\n0\n0\n1\n0\n1\n\n\n3\n45\n14\n210\n4200\n7\n-25\n1\n0\n0\n0\n1\n1\n0\n\n\n4\n51\n18\n203\n4100\n9\n-24\n0\n1\n0\n0\n1\n0\n1\n\n\n\n\n\n\n\n\nVisualizing the data\nThe bar chart below shows the number of penguins of each species on different islands, helping us identify patterns in species distribution. Interestingly, we observe: - Torgersen Island: Only Adelie penguins are present, with a population of about 30-40 individuals. - Dream Island: Has both Adelie and Chinstrap penguins, with Chinstrap being the dominant species. - Biscoe Island: Has both Adelie and Gentoo penguins, with Gentoo having the largest population overall.\nChinstrap penguins are only found on Dream Island, while Gentoo penguins are exclusive to Biscoe Island. Adelie penguins, on the other hand, are the most widespread, appearing on all three islands. Based on this distribution, the island where a penguin is found could be a useful feature for predicting its species.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n# Map species labels back to names\nspecies_map = {0: 'Adelie', 1: 'Chinstrap', 2: 'Gentoo'}\nspecies_island_counts = X_train.copy()\nspecies_island_counts[\"Species\"] = [species_map[label] for label in y_train]\n\n# Convert one-hot encoded islands back to a single column\nspecies_island_counts[\"Island\"] = species_island_counts[[\"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]].idxmax(axis=1)\nspecies_island_counts[\"Island\"] = species_island_counts[\"Island\"].str.replace(\"Island_\", \"\")\n\n# Count number of penguins per species per island\nplot_data = species_island_counts.groupby([\"Island\", \"Species\"]).size().reset_index(name=\"Count\")\n\n# Plot\nplt.figure(figsize=(8, 5))\nsns.barplot(data=plot_data, x=\"Island\", y=\"Count\", hue=\"Species\", palette=\"mako\")\nplt.xlabel(\"Island\")\nplt.ylabel(\"Number of Penguins\")\nplt.title(\"Penguin Species Distribution Across Islands\")\nplt.legend(title=\"Species\")\nplt.show()\n\n\n\n\n\n\n\n\nBased on the graph above, we can see that by simply looking at the islands, we can somewhat predict the species of the penguin. This is a good example of a feature that could help predict the species. However, the model would be much more efficient if each island only hosted one species of penguin. Since some islands have more than one species, we might want to explore additional features. For example, if a penguin is on Biscoe Island and has a certain Culmen length and Culmen depth, can we make more accurate predictions based on those measurements? To explore this, we will create a graph to assess whether including Culmen lenght and Culmen depth is a useful feature for predicting the species on each island.\n\n\n# Plotting the relationship between Culmen Length and Culmen Depth for each species on each island\nsns.relplot(data =train, hue=\"Species\", y = 'Culmen Depth (mm)', x =  'Culmen Length (mm)',col = 'Island')\n\n&lt;seaborn.axisgrid.FacetGrid at 0x149d2fc10&gt;\n\n\n\n\n\n\n\n\n\nThe graph above looks at the relationship between Culmen Depth (mm) and Culmen Length (mm) for different penguin species, separated by island. Each species is color-coded to highlight patterns in their beak dimensions. From this graph, we can observe: - Gentoo penguins (orange) tend to have longer culmen lengths and shallower culmen depths. - Adelie penguins (green) have moderate culmen lengths and a wide range of culmen depths. - Chinstrap penguins (blue) have longer culmen lenghts compared to Adelie penguins but exhibit similar culmen Depths. ## Can Culmen Features Help in Classification? Looking at the separability of species by island: - Biscoe Island: Gentoo and Adelie penguins are linearly separable, meaning a simple model could classify them effectively based on culmen features. - Dream Island: Chinstrap and Adelie penguins overlap in culmen depth, making them harder to separate linearly. However, their culmen lengths show some distinction, which could aid classification. - Torgersen Island: Since only Adelie penguins are found here, culmen features are irrelevant for classification on this island.\nThis suggests that culmen depth and length can be strong features for classifying species, especially when combined with island location. ## Exploring Culmen Features in relation to Flipper Lenght\n\nsns.relplot(data = train, y = 'Culmen Length (mm)', x =  'Flipper Length (mm)',  hue = 'Species').set(title='Relation between Flipper Length and Culmen Length')\nsns.relplot(data = train, y = 'Culmen Depth (mm)', x =  'Flipper Length (mm)',  hue = 'Species').set(title='Relation between Flipper Length and Culmen Depth')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe first graph explores the relationship between flipper length and culmen length across penguin species. Gentoo penguins have both longer flipper lengths and culmen lengths compared to the other species, making them easily distinguishable. Adelie penguins, in contrast, have shorter values for both features, clustering in the lower-left section of the graph. Chinstrap penguins overlap with Adelie penguins in flipper length but tend to have slightly longer culmen lengths, creating some classification challenges.\nThe second graph examines the relationship between flipper length and culmen depth. Here, Gentoo penguins are clearly separable from the other two species due to their significantly shallower culmen depths, forming a distinct cluster in the lower section. Howeber the Adelie and Chinstrap penguins overlap a lot more, particularly in flipper length and culmen depth. While Gentoo penguins can be classified easily, distinguishing between Adelie and Chinstrap penguins would be really difficult because of this clustering.\n\ntrain.groupby('Species').agg({\n    'Flipper Length (mm)': 'mean',\n    'Culmen Length (mm)': 'mean',\n    'Culmen Depth (mm)': 'mean'\n}).reset_index()\n\n\n\n\n\n\n\n\nSpecies\nFlipper Length (mm)\nCulmen Length (mm)\nCulmen Depth (mm)\n\n\n\n\n0\nAdelie Penguin (Pygoscelis adeliae)\n190.084034\n38.970588\n18.409244\n\n\n1\nChinstrap penguin (Pygoscelis antarctica)\n196.000000\n48.826316\n18.366667\n\n\n2\nGentoo penguin (Pygoscelis papua)\n216.752577\n47.073196\n14.914433\n\n\n\n\n\n\n\nThis code above calculates the mean values of flipper length, culmen length, and culmen depth for each penguin species using the .groupby() function. The table summarizes the average flipper length, culmen length, and culmen depth for each penguin species. Gentoo penguins have the longest flipper and culmen lengths but the shallowest culmen depth. Chinstrap penguins have longer culmen lengths than Adelie penguins but similar culmen depths. Adelie penguins have the shortest flipper and culmen lengths but slightly deeper culmens than Chinstrap. These differences highlight key features that can help classify penguin species."
  },
  {
    "objectID": "posts/Penguins/index.html#now-we-are-going-to-chose-feature-to-train-our-model",
    "href": "posts/Penguins/index.html#now-we-are-going-to-chose-feature-to-train-our-model",
    "title": "Classifying Palmer Penguins",
    "section": "Now we are going to chose feature to train our model",
    "text": "Now we are going to chose feature to train our model\nBy using the combinations function from the itertools package, we generate different combinations of categorical and continuous features. So we will pair categorical variables like Sex and Clutch Completion with continuous variables such as Culmen Length, Culmen Depth, and Flipper Length. This allows us to explore various feature combinations and evaluate which ones might be most useful for accurately classifying the penguin species.\n\nfrom itertools import combinations\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nall_qual_cols = [\"Clutch Completion\", \"Sex\", \"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\n\nbest_score = 0\nbest_features = None\n\nfor qual in all_qual_cols:\n    qual_cols = [col for col in X_train.columns if qual in col]  # Ensure categorical features are one-hot encoded\n    for pair in combinations(all_quant_cols, 2):\n        cols = qual_cols + list(pair)\n        \n        # Train a logistic regression model to evaluate feature combinations\n        model = LogisticRegression(max_iter=1000)  # Increased iterations for better convergence\n        scores = cross_val_score(model, X_train[cols], y_train, cv=5, scoring='accuracy')\n        \n        avg_score = np.mean(scores)\n        if avg_score &gt; best_score:\n            best_score = avg_score\n            best_features = cols\n\nprint(\"Best features:\", best_features)\n\nBest features: ['Sex_FEMALE', 'Sex_MALE', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n\n\nAccording to itertools, the best features to use are ‘Sex_FEMALE’, ‘Sex_MALE’, ‘Culmen Length (mm)’, and ‘Culmen Depth (mm)’. However, we wanted to explore how our model would perform based on our exploration of the island features along with the Culmen features. Thus, we will now reassign these as the best features and use them to train our model.\n\n#Rearranging Best featrues so that the first two columns are the quantitative columns and the rest are the qualitative columns\nbest_features = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\nbest_features\n\n['Culmen Length (mm)',\n 'Culmen Depth (mm)',\n 'Island_Biscoe',\n 'Island_Dream',\n 'Island_Torgersen']"
  },
  {
    "objectID": "posts/Penguins/index.html#let-us-now-prepare-our-test-dataset",
    "href": "posts/Penguins/index.html#let-us-now-prepare-our-test-dataset",
    "title": "Classifying Palmer Penguins",
    "section": "Let us now prepare our Test Dataset",
    "text": "Let us now prepare our Test Dataset\n\n# Load test data\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\n# Prepare test data\nX_test, y_test = prepare_data(test)"
  },
  {
    "objectID": "posts/Penguins/index.html#training-and-evaluating-our-model",
    "href": "posts/Penguins/index.html#training-and-evaluating-our-model",
    "title": "Classifying Palmer Penguins",
    "section": "Training and evaluating our Model",
    "text": "Training and evaluating our Model\nIn the code below, we use a Logistic Regression model and train it on the selected features: [‘Culmen Length (mm)’, ‘Culmen Depth (mm)’, ‘Island_Biscoe’, ‘Island_Dream’, ‘Island_Torgersen’]. We then evaluate the accuracy using the LR.score function. Our training accuracy was 99%, and our testing accuracy—measuring how well the model performed on unseen data—was 100%. The confusion matrix confirms that we correctly classified all penguins with no misclassifications. Specifically, our model correctly identified 31 Adelie, 11 Chinstrap, and 26 Gentoo penguins, achieving perfect classification.\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nLR = LogisticRegression()\nLR.fit(X_train[best_features], y_train)\n\n\n\n# Predict on test set\ny_pred = LR.predict(X_test[best_features])\n\n# Evaluate the model\nscore_train = LR.score(X_train[best_features], y_train)\nscore_test = LR.score(X_test[best_features], y_test)\n\nprint(\"Training Accuracy:\", score_train)\nprint(\"Test Accuracy:\", score_test)\n\nprint(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n\nTraining Accuracy: 0.9921875\nTest Accuracy: 1.0\n\nConfusion Matrix:\n [[31  0  0]\n [ 0 11  0]\n [ 0  0 26]]"
  },
  {
    "objectID": "posts/Penguins/index.html#plotting-our-results",
    "href": "posts/Penguins/index.html#plotting-our-results",
    "title": "Classifying Palmer Penguins",
    "section": "Plotting our results",
    "text": "Plotting our results\nThis code below helps us visualize the decision regions of our classification model by plotting how different penguin species are separated based on culmen features and island locations. It creates a grid of values for the culmen length and depth, predicts species across the grid. Each subplot represents a different island, showing how the model’s decision boundaries change depending on the island feature. This helps us understand how the model differentiates between Adelie, Chinstrap, and Gentoo penguins on each island.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y, title):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize=(7 * len(qual_features), 3))  # doing this to fit three plots side by side\n    fig.suptitle(title, fontsize=14)\n\n    # Create a grid\n    grid_x = np.linspace(x0.min(), x0.max(), 501)\n    grid_y = np.linspace(x1.min(), x1.max(), 501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    if len(qual_features) == 1:\n        axarr = [axarr] \n\n    for i, ax in enumerate(axarr):\n        XY = pd.DataFrame({\n            X.columns[0]: XX,\n            X.columns[1]: YY\n        })\n\n        for j in qual_features:\n            XY[j] = 0\n\n        XY[qual_features[i]] = 1\n\n        p = model.predict(XY)\n        p = p.reshape(xx.shape)\n        \n        # Use contour plot to visualize the predictions\n        ax.contourf(xx, yy, p, cmap=\"jet\", alpha=0.2, vmin=0, vmax=2)\n\n        ix = X[qual_features[i]] == 1\n        ax.scatter(x0[ix], x1[ix], c=y[ix], cmap=\"jet\", vmin=0, vmax=2)\n        \n        ax.set(xlabel=X.columns[0], ylabel=X.columns[1], title=qual_features[i])\n\n    patches = [Patch(color=color, label=spec) for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"])]\n    fig.legend(handles=patches, title=\"Species\", loc=\"upper right\")\n\n    plt.tight_layout(rect=[0, 0, 0.9, 1])\n    plt.show()\n\n# Run function for training and test sets\nplot_regions(LR, X_train[best_features], y_train, title=\"Training Set\")\nplot_regions(LR, X_test[best_features], y_pred, title=\"Test Set\")"
  }
]